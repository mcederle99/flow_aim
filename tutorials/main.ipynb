{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e3fc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/flow/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as gnn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17c9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_dict = {\"b_c\": 0, \"c_r\": 1, \"r_c\": 2, \"c_t\": 3, \"t_c\": 4, \"c_l\": 5,\n",
    "              \"l_c\": 6, \"c_b\": 7, \":center_0\": 8, \":center_1\": 9, \":center_2\": 10,\n",
    "              \":center_12\": 10, \":center_3\": 11, \":center_4\": 12, \":center_5\": 13,\n",
    "              \":center_6\": 14, \":center_7\": 15, \":center_8\": 16, \":center_13\": 16,\n",
    "              \":center_9\": 17, \":center_10\": 18, \":center_11\": 19}\n",
    "\n",
    "routes_dict = {('t_c', 'c_l'): 0, ('t_c', 'c_b'): 1, ('t_c', 'c_r'): 2, ('r_c', 'c_t'): 3,\n",
    "               ('r_c', 'c_l'): 4, ('r_c', 'c_b'): 5, ('b_c', 'c_r'): 6, ('b_c', 'c_t'): 7,\n",
    "               ('b_c', 'c_l'): 8, ('l_c', 'c_b'): 9, ('l_c', 'c_r'): 10, ('l_c', 'c_t'): 11}\n",
    "\n",
    "all_vehicles = {}\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "conflicting_routes_matrix = np.zeros((12,12))\n",
    "for i in range(12):\n",
    "    for j in range(12):\n",
    "        if i == 0:\n",
    "            if j in (4,8):\n",
    "                conflicting_routes_matrix[i][j] = 1\n",
    "        elif i == 1:\n",
    "            if j in (4,5,8,9,10,11):\n",
    "                conflicting_routes_matrix[i][j] = 1\n",
    "        elif i == 2:\n",
    "            if j in (4,5,6,7,8,10,11):\n",
    "                conflicting_routes_matrix[i][j] = 1\n",
    "        elif i == 3:\n",
    "            if j in (7,11):\n",
    "                conflicting_routes_matrix[i][j] = 1\n",
    "        elif i == 4:\n",
    "            if j in (0,1,2,7,8,11):\n",
    "                conflicting_routes_matrix[i][j] = 1\n",
    "        elif i == 5:\n",
    "            if j in (1,2,7,8,9,10,11):\n",
    "                conflicting_routes_matrix[i][j] = 1\n",
    "        elif i == 6:\n",
    "            if j in (2,10):\n",
    "                conflicting_routes_matrix[i][j] = 1\n",
    "        elif i == 7:\n",
    "            if j in (2,3,4,5,10,11):\n",
    "                conflicting_routes_matrix[i][j] = 1\n",
    "        elif i == 8:\n",
    "            if j in (0,1,2,4,5,10,11):\n",
    "                conflicting_routes_matrix[i][j] = 1\n",
    "        elif i == 9:\n",
    "            if j in (1,5):\n",
    "                conflicting_routes_matrix[i][j] = 1\n",
    "        elif i == 10:\n",
    "            if j in (1,2,5,6,7,8):\n",
    "                conflicting_routes_matrix[i][j] = 1\n",
    "        else:\n",
    "            if j in (1,2,3,4,5,7,8):\n",
    "                conflicting_routes_matrix[i][j] = 1\n",
    "                \n",
    "routes_edges_matrix = np.zeros((12,20))\n",
    "for i in range(12):\n",
    "    if i == 0:\n",
    "        routes_edges_matrix[i][4] = 1\n",
    "        routes_edges_matrix[i][8] = 2\n",
    "        routes_edges_matrix[i][5] = 3\n",
    "    elif i == 1:\n",
    "        routes_edges_matrix[i][4] = 1\n",
    "        routes_edges_matrix[i][9] = 2\n",
    "        routes_edges_matrix[i][7] = 3\n",
    "    elif i == 2:\n",
    "        routes_edges_matrix[i][4] = 1\n",
    "        routes_edges_matrix[i][10] = 2\n",
    "        routes_edges_matrix[i][1] = 3\n",
    "    elif i == 3:\n",
    "        routes_edges_matrix[i][2] = 1\n",
    "        routes_edges_matrix[i][11] = 2\n",
    "        routes_edges_matrix[i][3] = 3\n",
    "    elif i == 4:\n",
    "        routes_edges_matrix[i][2] = 1\n",
    "        routes_edges_matrix[i][12] = 2\n",
    "        routes_edges_matrix[i][5] = 3\n",
    "    elif i == 5:\n",
    "        routes_edges_matrix[i][2] = 1\n",
    "        routes_edges_matrix[i][13] = 2\n",
    "        routes_edges_matrix[i][7] = 3\n",
    "    elif i == 6:\n",
    "        routes_edges_matrix[i][0] = 1\n",
    "        routes_edges_matrix[i][14] = 2\n",
    "        routes_edges_matrix[i][1] = 3\n",
    "    elif i == 7:\n",
    "        routes_edges_matrix[i][0] = 1\n",
    "        routes_edges_matrix[i][15] = 2\n",
    "        routes_edges_matrix[i][3] = 3\n",
    "    elif i == 8:\n",
    "        routes_edges_matrix[i][0] = 1\n",
    "        routes_edges_matrix[i][16] = 2\n",
    "        routes_edges_matrix[i][5] = 3\n",
    "    elif i == 9:\n",
    "        routes_edges_matrix[i][6] = 1\n",
    "        routes_edges_matrix[i][17] = 2\n",
    "        routes_edges_matrix[i][7] = 3\n",
    "    elif i == 10:\n",
    "        routes_edges_matrix[i][6] = 1\n",
    "        routes_edges_matrix[i][18] = 2\n",
    "        routes_edges_matrix[i][1] = 3\n",
    "    else:\n",
    "        routes_edges_matrix[i][6] = 1\n",
    "        routes_edges_matrix[i][19] = 2\n",
    "        routes_edges_matrix[i][3] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d43a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi, sin, cos, linspace\n",
    "\n",
    "from flow.core.params import InitialConfig\n",
    "from flow.core.params import TrafficLightParams\n",
    "from flow.networks.base import Network\n",
    "\n",
    "ADDITIONAL_NET_PARAMS = {\n",
    "    # radius of the circular components\n",
    "    \"radius_ring\": 30,\n",
    "    # number of lanes\n",
    "    \"lanes\": 1,\n",
    "    # speed limit for all edges\n",
    "    \"speed_limit\": 30,\n",
    "    # resolution of the curved portions\n",
    "    \"resolution\": 40\n",
    "}\n",
    "\n",
    "class IntersectionNetwork(Network):\n",
    "    \"\"\"Figure eight network class.\n",
    "\n",
    "    The figure eight network is an extension of the ring road network: Two\n",
    "    rings, placed at opposite ends of the network, are connected by an\n",
    "    intersection with road segments of length equal to the diameter of the\n",
    "    rings. Serves as a simulation of a closed ring intersection.\n",
    "\n",
    "    Requires from net_params:\n",
    "\n",
    "    * **ring_radius** : radius of the circular portions of the network. Also\n",
    "      corresponds to half the length of the perpendicular straight lanes.\n",
    "    * **resolution** : number of nodes resolution in the circular portions\n",
    "    * **lanes** : number of lanes in the network\n",
    "    * **speed** : max speed of vehicles in the network\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    >>> from flow.core.params import NetParams\n",
    "    >>> from flow.core.params import VehicleParams\n",
    "    >>> from flow.core.params import InitialConfig\n",
    "    >>> from flow.networks import FigureEightNetwork\n",
    "    >>>\n",
    "    >>> network = FigureEightNetwork(\n",
    "    >>>     name='figure_eight',\n",
    "    >>>     vehicles=VehicleParams(),\n",
    "    >>>     net_params=NetParams(\n",
    "    >>>         additional_params={\n",
    "    >>>             'radius_ring': 50,\n",
    "    >>>             'lanes': 75,\n",
    "    >>>             'speed_limit': 30,\n",
    "    >>>             'resolution': 40\n",
    "    >>>         },\n",
    "    >>>     )\n",
    "    >>> )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 name,\n",
    "                 vehicles,\n",
    "                 net_params,\n",
    "                 initial_config=InitialConfig(),\n",
    "                 traffic_lights=TrafficLightParams()):\n",
    "        \"\"\"Initialize a figure 8 network.\"\"\"\n",
    "        for p in ADDITIONAL_NET_PARAMS.keys():\n",
    "            if p not in net_params.additional_params:\n",
    "                raise KeyError('Network parameter \"{}\" not supplied'.format(p))\n",
    "\n",
    "        ring_radius = net_params.additional_params[\"radius_ring\"]\n",
    "        self.ring_edgelen = ring_radius * np.pi / 2.\n",
    "        self.intersection_len = 2 * ring_radius\n",
    "        self.junction_len = 2.9 + 3.3 * net_params.additional_params[\"lanes\"]\n",
    "        self.inner_space_len = 0.28\n",
    "\n",
    "        # # instantiate \"length\" in net params\n",
    "        # net_params.additional_params[\"length\"] = \\\n",
    "        #     6 * self.ring_edgelen + 2 * self.intersection_len + \\\n",
    "        #     2 * self.junction_len + 10 * self.inner_space_len\n",
    "\n",
    "        super().__init__(name, vehicles, net_params, initial_config,\n",
    "                         traffic_lights)\n",
    "\n",
    "    def specify_nodes(self, net_params):\n",
    "        \"\"\"See parent class.\"\"\"\n",
    "        r = net_params.additional_params[\"radius_ring\"]\n",
    "\n",
    "        nodes = [{\n",
    "            \"id\": \"center\",\n",
    "            \"x\": 0,\n",
    "            \"y\": 0,\n",
    "            #\"radius\": 10,\n",
    "            \"radius\": (2.9 + 3.3 * net_params.additional_params[\"lanes\"])/2,\n",
    "            \"type\": \"priority\"\n",
    "        }, {\n",
    "            \"id\": \"right\",\n",
    "            \"x\": r,\n",
    "            \"y\": 0,\n",
    "            \"type\": \"priority\"\n",
    "        }, {\n",
    "            \"id\": \"top\",\n",
    "            \"x\": 0,\n",
    "            \"y\": r,\n",
    "            \"type\": \"priority\"\n",
    "        }, {\n",
    "            \"id\": \"left\",\n",
    "            \"x\": -r,\n",
    "            \"y\": 0,\n",
    "            \"type\": \"priority\"\n",
    "        }, {\n",
    "            \"id\": \"bottom\",\n",
    "            \"x\": 0,\n",
    "            \"y\": -r,\n",
    "            \"type\": \"priority\"\n",
    "        }]\n",
    "\n",
    "        return nodes\n",
    "\n",
    "    def specify_edges(self, net_params):\n",
    "        \"\"\"See parent class.\"\"\"\n",
    "        r = net_params.additional_params[\"radius_ring\"]\n",
    "        resolution = net_params.additional_params[\"resolution\"]\n",
    "        ring_edgelen = 3 * r * pi / 2.\n",
    "        intersection_edgelen = 2 * r\n",
    "\n",
    "        # intersection edges\n",
    "        edges = [{\n",
    "            \"id\": \"b_c\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": \"78\",\n",
    "            \"from\": \"bottom\",\n",
    "            \"to\": \"center\",\n",
    "            \"length\": intersection_edgelen / 2\n",
    "        }, {\n",
    "            \"id\": \"c_t\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": 78,\n",
    "            \"from\": \"center\",\n",
    "            \"to\": \"top\",\n",
    "            \"length\": intersection_edgelen / 2\n",
    "        }, {\n",
    "            \"id\": \"r_c\",\n",
    "            \"type\": \"edgeType\",\n",
    "            \"priority\": 78,\n",
    "            \"from\": \"right\",\n",
    "            \"to\": \"center\",\n",
    "            \"length\": intersection_edgelen / 2\n",
    "        }, {\n",
    "            \"id\": \"c_l\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": 46,\n",
    "            \"from\": \"center\",\n",
    "            \"to\": \"left\",\n",
    "            \"length\": intersection_edgelen / 2\n",
    "        }, {\n",
    "            \"id\": \"t_c\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": 78,\n",
    "            \"from\": \"top\",\n",
    "            \"to\": \"center\",\n",
    "            \"length\": intersection_edgelen / 2\n",
    "        }, {\n",
    "            \"id\": \"c_r\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": 46,\n",
    "            \"from\": \"center\",\n",
    "            \"to\": \"right\",\n",
    "            \"length\": intersection_edgelen / 2\n",
    "        }, {\n",
    "            \"id\": \"l_c\",\n",
    "            \"type\": \"edgeType\",\n",
    "            \"priority\": 78,\n",
    "            \"from\": \"left\",\n",
    "            \"to\": \"center\",\n",
    "            \"length\": intersection_edgelen / 2\n",
    "        }, {\n",
    "            \"id\": \"c_b\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": \"78\",\n",
    "            \"from\": \"center\",\n",
    "            \"to\": \"bottom\",\n",
    "            \"length\": intersection_edgelen / 2\n",
    "        }]\n",
    "\n",
    "        return edges\n",
    "\n",
    "    def specify_types(self, net_params):\n",
    "        \"\"\"See parent class.\"\"\"\n",
    "        lanes = net_params.additional_params[\"lanes\"]\n",
    "        speed_limit = net_params.additional_params[\"speed_limit\"]\n",
    "        types = [{\n",
    "            \"id\": \"edgeType\",\n",
    "            \"numLanes\": lanes,\n",
    "            \"speed\": speed_limit\n",
    "        }]\n",
    "\n",
    "        return types\n",
    "\n",
    "    def specify_routes(self, net_params):\n",
    "        \"\"\"See parent class.\"\"\"\n",
    "        rts = {\n",
    "            \"r_c\":\n",
    "                [([\"r_c\", \"c_l\"], 1/3), ([\"r_c\", \"c_t\"], 1/3),\n",
    "                    ([\"r_c\", \"c_b\"], 1/3)],\n",
    "            \"b_c\":\n",
    "                [([\"b_c\", \"c_t\"], 1/3), ([\"b_c\", \"c_l\"], 1/3),\n",
    "                    ([\"b_c\", \"c_r\"], 1/3)],\n",
    "            \"t_c\":\n",
    "                [([\"t_c\", \"c_b\"], 1/3), ([\"t_c\", \"c_l\"], 1/3),\n",
    "                    ([\"t_c\", \"c_r\"], 1/3)],\n",
    "            \"l_c\":\n",
    "                [([\"l_c\", \"c_r\"], 1/3), ([\"l_c\", \"c_t\"], 1/3),\n",
    "                    ([\"l_c\", \"c_b\"], 1/3)],\n",
    "            \"c_r\":\n",
    "                [\"c_r\"],\n",
    "            \"c_l\":\n",
    "                [\"c_l\"],\n",
    "            \"c_t\":\n",
    "                [\"c_t\"],\n",
    "            \"c_b\":\n",
    "                [\"c_b\"],\n",
    "            \"human_0\":\n",
    "                [\"r_c\", \"c_l\"],\n",
    "            \"human_1\":\n",
    "                [\"b_c\", \"c_l\"],\n",
    "            }\n",
    "\n",
    "        return rts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7c3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.envs.base import Env\n",
    "from gym.spaces.box import Box\n",
    "from gym.spaces import Tuple\n",
    "from gym.spaces import Discrete\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "ADDITIONAL_ENV_PARAMS = {\n",
    "    \"max_accel\": 5,\n",
    "    \"max_decel\": -5,\n",
    "}\n",
    "\n",
    "class myEnv(Env):\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        num_actions = self.initial_vehicles.num_rl_vehicles\n",
    "        accel_ub = self.env_params.additional_params[\"max_accel\"]\n",
    "        accel_lb = - abs(self.env_params.additional_params[\"max_decel\"])\n",
    "\n",
    "        return Box(low=accel_lb,\n",
    "                   high=accel_ub,\n",
    "                   shape=(num_actions,))\n",
    "    \n",
    "    @property\n",
    "    def observation_space(self):\n",
    "        nodes = {}\n",
    "        for i in self.k.vehicle.get_ids():\n",
    "            nodes[i] = (Box(low=-float(\"inf\"), high=float(\"inf\"), shape=(1,)), # POSITION\n",
    "                        Box(low=0, high=float(\"inf\"), shape=(1,)),             # VELOCITY \n",
    "                        Box(low=0, high=float(\"inf\"), shape=(1,)),             # ACCELERATION\n",
    "                        Discrete(2),                                           # CONTROLLABLE\n",
    "                        Box(low=-float(\"inf\"), high=float(\"inf\"), shape=(2,)), # COORDINATES\n",
    "                        Box(low=-float(\"inf\"), high=float(\"inf\"), shape=(1,)), # HEADING ANGLE\n",
    "                        Discrete(20),                                          # EDGE\n",
    "                        Discrete(12),                                          # ROUTE\n",
    "                       )\n",
    "            \n",
    "        return nodes\n",
    "    \n",
    "    def _apply_rl_actions(self, rl_actions):\n",
    "        # the names of all autonomous (RL) vehicles in the network\n",
    "        rl_ids = self.k.vehicle.get_rl_ids()\n",
    "        # use the base environment method to convert actions into accelerations for the rl vehicles\n",
    "        self.k.vehicle.apply_acceleration(rl_ids, rl_actions)\n",
    "        \n",
    "    def get_state(self, **kwargs):\n",
    "        \n",
    "        # the get_ids() method is used to get the names of all vehicles in the network\n",
    "        ids = self.k.vehicle.get_ids()\n",
    "        state = {}\n",
    "        \n",
    "        for q in ids:\n",
    "            \n",
    "            # POSITION\n",
    "            if q not in all_vehicles.keys():\n",
    "                all_vehicles[q] = False\n",
    "            \n",
    "            pos = -42\n",
    "            old_pos = -12\n",
    "            raw_pos = self.k.vehicle.get_position(q)\n",
    "            if self.k.vehicle.get_route(q) == '':\n",
    "                i = 0\n",
    "            else:\n",
    "                i = routes_dict[self.k.vehicle.get_route(q)]\n",
    "            if self.k.vehicle.get_edge(q) == '':\n",
    "                j = 5\n",
    "            else:\n",
    "                j = edges_dict[self.k.vehicle.get_edge(q)]\n",
    "            if routes_edges_matrix[i][j] == 1:\n",
    "                pos = raw_pos - 42\n",
    "            elif routes_edges_matrix[i][j] == 2:\n",
    "                if i in (1,4,7,10):\n",
    "                    pos = raw_pos - 12\n",
    "                elif i in (2,5,8,11):\n",
    "                    if not all_vehicles[q]:\n",
    "                        if abs(pos+12-raw_pos) > 3:\n",
    "                            all_vehicles[q] = True\n",
    "                            pos = pos + raw_pos\n",
    "                        else:\n",
    "                            pos = raw_pos - 12\n",
    "                    else:\n",
    "                        pos = raw_pos + 4 - 12\n",
    "                else:\n",
    "                    old_pos = pos\n",
    "                    pos = raw_pos - 12\n",
    "                    ang_coeff = 12/7\n",
    "                    rel_displ = ang_coeff*(pos-old_pos)\n",
    "                    pos = old_pos + rel_displ\n",
    "            else:\n",
    "                pos = raw_pos\n",
    "                \n",
    "            # VELOCITY\n",
    "            vel = self.k.vehicle.get_speed(q)\n",
    "            \n",
    "            # ACCELERATION\n",
    "            acc = self.k.vehicle.get_realized_accel(q)\n",
    "            if acc == None:\n",
    "                acc = 0\n",
    "            \n",
    "            # CONTROLLABLE\n",
    "            if self.k.vehicle.get_type(q) == 'human':\n",
    "                contr = 0\n",
    "            else:\n",
    "                contr = 1\n",
    "                \n",
    "            # COORDINATES\n",
    "            coord = self.k.vehicle.get_2d_position(q)\n",
    "            \n",
    "            # HEADING ANGLE\n",
    "            angle = self.k.vehicle.get_orientation(q)[2]\n",
    "            \n",
    "            # EDGE\n",
    "            if self.k.vehicle.get_edge(q) == '':\n",
    "                edge = 5\n",
    "            else:\n",
    "                edge = edges_dict[self.k.vehicle.get_edge(q)]\n",
    "                              \n",
    "            # ROUTE\n",
    "            if self.k.vehicle.get_route(q) == '':\n",
    "                route = 0\n",
    "            else:\n",
    "                route = routes_dict[self.k.vehicle.get_route(q)]\n",
    "\n",
    "                                \n",
    "            state[q] = (pos, vel, acc, contr, coord, angle, edge, route)\n",
    "                                \n",
    "        return state\n",
    "                                \n",
    "    def compute_reward(self, rl_actions, state=None, **kwargs):\n",
    "        speed_limit = 25\n",
    "        w_v = 0.03\n",
    "        w_a = 0.01\n",
    "        w_i = 0.01\n",
    "        w_c = 1\n",
    "        #w_r = 0.01 IN STALLO PER ORA\n",
    "        \n",
    "        # the get_ids() method is used to get the names of all vehicles in the network\n",
    "        ids = self.k.vehicle.get_ids()\n",
    "        crash = self.k.simulation.check_collision()\n",
    "        \n",
    "        # VELOCITY TERM\n",
    "        speeds = self.k.vehicle.get_speed(ids)\n",
    "        if speeds == []:\n",
    "            mean_speed = 0\n",
    "        else:\n",
    "            mean_speed = np.mean(speeds)\n",
    "        \"\"\"\n",
    "        rel_speed = mean_speed/speed_limit\n",
    "        if rel_speed <= 0.5:\n",
    "            Rv = 2*rel_speed\n",
    "        elif 0.5 < rel_speed <= 1:\n",
    "            Rv = 1\n",
    "        else:\n",
    "            Rv = 6-5*rel_speed\n",
    "        \"\"\"\n",
    "        if crash:\n",
    "            Rv = 0\n",
    "        else:\n",
    "            Rv = mean_speed\n",
    "            \n",
    "        # ACTION TERM\n",
    "        if speeds == [] or len(rl_actions) == 0:\n",
    "            Ra = 0\n",
    "        else:\n",
    "            Ra = -np.mean(np.abs(rl_actions))\n",
    "\n",
    "        # IDLE TERM\n",
    "        if len(speeds) > 0:\n",
    "            if max(speeds) < 0.3:\n",
    "                Ri = -1\n",
    "            else:\n",
    "                Ri = 0\n",
    "        else:\n",
    "            Ri = 0\n",
    "        \n",
    "        # COLLISION TERM\n",
    "        if crash:\n",
    "            Rc = -1\n",
    "        else:\n",
    "            Rc = 0\n",
    "            \n",
    "        # RELUCTANCE TERM\n",
    "        # IN STALLO PER ORA\n",
    "\n",
    "        R = w_v*Rv + w_a*Ra + w_i*Ri + w_c*Rc\n",
    "\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "105e2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import VehicleParams\n",
    "from flow.controllers import IDMController, ContinuousRouter\n",
    "from flow.core.params import SumoParams, EnvParams, InitialConfig, NetParams\n",
    "from flow.controllers import RLController\n",
    "\n",
    "vehicles = VehicleParams()\n",
    "\n",
    "vehicles.add(veh_id=\"human\",\n",
    "             acceleration_controller=(IDMController, {}),\n",
    "             routing_controller=(ContinuousRouter, {}),\n",
    "             num_vehicles=2,\n",
    "             color='green')\n",
    "\n",
    "from flow.core.params import InFlows\n",
    "\n",
    "inflow = InFlows()\n",
    "\n",
    "inflow.add(veh_type=\"rl\",\n",
    "           edge=\"b_c\",\n",
    "           probability=0.05,\n",
    "           #depart_speed=\"random\",\n",
    "          )\n",
    "inflow.add(veh_type=\"rl\",\n",
    "           edge=\"t_c\",\n",
    "           probability=0.1,\n",
    "           #depart_speed=\"random\",\n",
    "          )\n",
    "inflow.add(veh_type=\"rl\",\n",
    "           edge=\"l_c\",\n",
    "           probability=0.1,\n",
    "           #depart_speed=\"random\",\n",
    "          )\n",
    "inflow.add(veh_type=\"rl\",\n",
    "           edge=\"r_c\",\n",
    "           probability=0.05,\n",
    "           #depart_speed=\"random\",\n",
    "          )\n",
    "\n",
    "\n",
    "sim_params = SumoParams(sim_step=0.1, render=True)\n",
    "\n",
    "initial_config = InitialConfig()\n",
    "\n",
    "env_params = EnvParams(additional_params=ADDITIONAL_ENV_PARAMS)\n",
    "\n",
    "additional_net_params = ADDITIONAL_NET_PARAMS.copy()\n",
    "net_params = NetParams(additional_params=additional_net_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb67b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_edges(env, state):\n",
    "    \n",
    "    dimensions_matrix = np.array([[25/4,0], [0,1]])\n",
    "    edges = {}\n",
    "    edges_type = {}\n",
    "    for i in env.k.vehicle.get_ids():\n",
    "        for j in env.k.vehicle.get_ids():\n",
    "            if conflicting_routes_matrix[state[i][7]][state[j][7]] == 1:\n",
    "                if (routes_edges_matrix[state[i][7]][state[i][6]] != 3) and (routes_edges_matrix[state[j][7]][state[j][6]] != 3):\n",
    "                    # DISTANCE\n",
    "                    rotation_matrix = np.array([[np.cos(state[i][5]), -np.sin(state[i][5])],\n",
    "                                               [np.sin(state[i][5]), np.cos(state[i][5])]])\n",
    "                    sigma_matrix = np.matmul(np.matmul(rotation_matrix, dimensions_matrix),\n",
    "                                             rotation_matrix.transpose())\n",
    "                    cartesian_dist = np.array(state[j][4]) - np.array(state[i][4])\n",
    "                    d_ij = np.matmul(np.matmul(cartesian_dist.transpose(), inv(sigma_matrix)),\n",
    "                                     cartesian_dist)\n",
    "                    d_ij = 1/np.sqrt(d_ij)\n",
    "                \n",
    "                    # BEARING\n",
    "                    coord_j = np.array(state[j][4])\n",
    "                    coord_i = np.array(state[i][4])\n",
    "                    py = coord_i[1] - coord_j[1]\n",
    "                    px = coord_i[0] - coord_j[1]\n",
    "                    chi_ij = np.arctan(py/px) - state[j][5]\n",
    "                    \n",
    "                    # PRIORITY\n",
    "                    # IN STALLO PER ORA\n",
    "                    \n",
    "                    edges_type[(i,j)] = 'crossing'\n",
    "                    \n",
    "                    edges[(i,j)] = (d_ij, chi_ij)\n",
    "                \n",
    "                elif np.argmax(routes_edges_matrix[state[i][7]]) == np.argmax(routes_edges_matrix[state[j][7]]):\n",
    "                    if state[i][0] > state[j][0]:\n",
    "                        # DISTANCE\n",
    "                        rotation_matrix = np.array([[np.cos(state[i][5]), -np.sin(state[i][5])],\n",
    "                                                   [np.sin(state[i][5]), np.cos(state[i][5])]])\n",
    "                        sigma_matrix = np.matmul(np.matmul(rotation_matrix, dimensions_matrix),\n",
    "                                                 rotation_matrix.transpose())\n",
    "                        cartesian_dist = np.array(state[j][4]) - np.array(state[i][4])\n",
    "                        d_ij = np.matmul(np.matmul(cartesian_dist.transpose(), inv(sigma_matrix)),\n",
    "                                         cartesian_dist)\n",
    "                        d_ij = 1/np.sqrt(d_ij)\n",
    "\n",
    "                        # BEARING\n",
    "                        coord_j = np.array(state[j][4])\n",
    "                        coord_i = np.array(state[i][4])\n",
    "                        py = coord_i[1] - coord_j[1]\n",
    "                        px = coord_i[0] - coord_j[1]\n",
    "                        chi_ij = np.arctan(py/px) - state[j][5]\n",
    "\n",
    "                        # PRIORITY\n",
    "                        # IN STALLO PER ORA\n",
    "                        \n",
    "                        edges_type[(i,j)] = 'same_lane'\n",
    "                        \n",
    "                        edges[(i,j)] = (d_ij, chi_ij)\n",
    "            \n",
    "            elif state[i][7] == state[j][7]:\n",
    "                if state[i][0] > state[j][0]:\n",
    "                    # DISTANCE\n",
    "                    rotation_matrix = np.array([[np.cos(state[i][5]), -np.sin(state[i][5])],\n",
    "                                               [np.sin(state[i][5]), np.cos(state[i][5])]])\n",
    "                    sigma_matrix = np.matmul(np.matmul(rotation_matrix, dimensions_matrix),\n",
    "                                             rotation_matrix.transpose())\n",
    "                    cartesian_dist = np.array(state[j][4]) - np.array(state[i][4])\n",
    "                    d_ij = np.matmul(np.matmul(cartesian_dist.transpose(), inv(sigma_matrix)),\n",
    "                                     cartesian_dist)\n",
    "                    d_ij = 1/np.sqrt(d_ij)\n",
    "\n",
    "                    # BEARING\n",
    "                    coord_j = np.array(state[j][4])\n",
    "                    coord_i = np.array(state[i][4])\n",
    "                    py = coord_i[1] - coord_j[1]\n",
    "                    px = coord_i[0] - coord_j[1]\n",
    "                    chi_ij = np.arctan(py/px) - state[j][5]\n",
    "\n",
    "                    # PRIORITY\n",
    "                    # IN STALLO PER ORA\n",
    "                    \n",
    "                    edges_type[(i,j)] = 'same_lane'\n",
    "                    \n",
    "                    edges[(i,j)] = (d_ij, chi_ij)\n",
    "            \n",
    "            elif state[i][6] == state[j][6]:\n",
    "                if state[i][0] > state[j][0]:\n",
    "                    # DISTANCE\n",
    "                    rotation_matrix = np.array([[np.cos(state[i][5]), -np.sin(state[i][5])],\n",
    "                                               [np.sin(state[i][5]), np.cos(state[i][5])]])\n",
    "                    sigma_matrix = np.matmul(np.matmul(rotation_matrix, dimensions_matrix),\n",
    "                                             rotation_matrix.transpose())\n",
    "                    cartesian_dist = np.array(state[j][4]) - np.array(state[i][4])\n",
    "                    d_ij = np.matmul(np.matmul(cartesian_dist.transpose(), inv(sigma_matrix)),\n",
    "                                     cartesian_dist)\n",
    "                    d_ij = 1/np.sqrt(d_ij)\n",
    "\n",
    "                    # BEARING\n",
    "                    coord_j = np.array(state[j][4])\n",
    "                    coord_i = np.array(state[i][4])\n",
    "                    py = coord_i[1] - coord_j[1]\n",
    "                    px = coord_i[0] - coord_j[1]\n",
    "                    chi_ij = np.arctan(py/px) - state[j][5]\n",
    "\n",
    "                    # PRIORITY\n",
    "                    # IN STALLO PER ORA\n",
    "\n",
    "                    edges_type[(i,j)] = 'same_lane'\n",
    "                    \n",
    "                    edges[(i,j)] = (d_ij, chi_ij)\n",
    "                    \n",
    "    return edges, edges_type\n",
    "\n",
    "def compute_rp(edges):\n",
    "    d = np.inf\n",
    "    for i in range(len(list(edges.values()))):\n",
    "        d_i = 1/list(edges.values())[i][0]\n",
    "        if d_i < d:\n",
    "            d = d_i\n",
    "    \n",
    "    return -1/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad90850",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, nodes_list, edges_list):\n",
    "        self.nodes = [i for i in range(len(nodes_list))]\n",
    "        self.edges = []\n",
    "        for e in edges_list:\n",
    "            self.edges = self.edges + [(nodes_list.index(e[0]), nodes_list.index(e[1]))]\n",
    "        \n",
    "        self.edata = {}\n",
    "        self.ndata = {}\n",
    "        self.sparse_adj = torch.zeros([2,len(self.edges)], dtype=torch.int64, device=device)\n",
    "        for k in range(len(self.edges)):\n",
    "            self.sparse_adj[0][k] = self.edges[k][0]\n",
    "            self.sparse_adj[1][k] = self.edges[k][1]\n",
    "        \n",
    "    def num_nodes(self):\n",
    "        return len(self.nodes)\n",
    "    \n",
    "    def num_edges(self):\n",
    "        return len(self.edges)\n",
    "    \n",
    "    def insert_node_features(self, nodes_feat):\n",
    "        self.ndata['x'] = nodes_feat\n",
    "        \n",
    "    def insert_edge_features(self, edges_feat, edges_types): \n",
    "        self.edata['x'] = edges_feat\n",
    "        self.edata['type'] = list(edges_types.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b51b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNLayer(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, num_rels):\n",
    "        super(RGCNLayer, self).__init__()\n",
    "        self.in_feat = in_feat # encoded_nodes_features_dim + encoded_edges_features_dim\n",
    "        self.out_feat = out_feat # encoded_nodes_features_dim\n",
    "        self.num_rels = num_rels # 2 per ora\n",
    "        \n",
    "        # weight tensors\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.num_rels, self.out_feat,\n",
    "                                                self.in_feat))\n",
    "        self.weight_0 = nn.Parameter(torch.Tensor(self.out_feat, self.out_feat))\n",
    "            \n",
    "        # initialize trainable parameters\n",
    "        nn.init.xavier_uniform_(self.weight,\n",
    "                                gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.weight_0,\n",
    "                                gain=nn.init.calculate_gain('relu'))\n",
    "            \n",
    "    def forward(self, g):\n",
    "        \n",
    "        weight = self.weight\n",
    "        \n",
    "        enh_adj = {}\n",
    "        for i in range(g.num_nodes()):\n",
    "            for j in range(g.num_nodes()):\n",
    "                if (j,i) in g.edges:\n",
    "                    enh_adj[(i,j)] = torch.cat((g.ndata['x'][j], g.edata['x'][g.edges.index((j,i))]))\n",
    "                else:\n",
    "                    enh_adj[(i,j)] = torch.zeros([1,], device=device)\n",
    "        \n",
    "        types = ('same_lane', 'crossing')\n",
    "        out = torch.zeros([g.num_nodes(),64], device=device)\n",
    "        for i in range(g.num_nodes()):\n",
    "            message = torch.zeros([64,], device=device)\n",
    "            for r in types:\n",
    "                max_value = -np.inf*torch.ones([64,], device=device)\n",
    "                for j in range(g.num_nodes()):\n",
    "                    if torch.sum(enh_adj[(i,j)]) != 0:\n",
    "                        if g.edata['type'][g.edges.index((j,i))] == r:\n",
    "                            temp = torch.matmul(weight[types.index(r)], enh_adj[(i,j)])\n",
    "                            max_value = torch.maximum(max_value, temp)\n",
    "                if torch.sum(max_value) != -np.inf:\n",
    "                    message = message + max_value\n",
    "            out[i] = message + torch.matmul(self.weight_0, g.ndata['x'][i])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e650920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, node_dim=4, edge_dim=2, action_dim=1, max_action=5):\n",
    "        super(Actor, self).__init__()\n",
    "        \n",
    "        # node encoder\n",
    "        self.n_enc = nn.Linear(node_dim, 64)\n",
    "        # edge encoder\n",
    "        self.e_enc = nn.Linear(edge_dim, 32)\n",
    "        \n",
    "        # first RGCN layer\n",
    "        self.RGCN1 = RGCNLayer(96, 64, 2)\n",
    "        # GAT layer\n",
    "        self.GAT = gnn.GATConv(64, 64, add_self_loops=False, edge_dim=32)\n",
    "        # second RGCN layer\n",
    "        self.RGCN2 = RGCNLayer(96, 64, 2)\n",
    "        \n",
    "        # node decoder\n",
    "        self.n_dec = nn.Linear(64, action_dim)\n",
    "        \n",
    "        self.max_action = max_action\n",
    "        \n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, nodes, edges, edges_type):\n",
    "        n_feat = list(nodes.values())\n",
    "        n_feat = torch.as_tensor(n_feat, dtype=torch.float32, device=device)\n",
    "        e_feat = list(edges.values())\n",
    "        e_feat = torch.as_tensor(e_feat, dtype=torch.float32, device=device)\n",
    "        \n",
    "        # node encoding\n",
    "        if n_feat.size()[0] == 0:\n",
    "            n = n_feat\n",
    "        else:\n",
    "            n = self.n_enc(n_feat) # n should be num_nodes*64\n",
    "            n = F.relu(n)\n",
    "        \n",
    "        # edge encoding\n",
    "        if e_feat.size()[0] == 0:\n",
    "            e = e_feat\n",
    "        else:\n",
    "            e = self.e_enc(e_feat) # e should be num_edges*32\n",
    "            e = F.relu(e)\n",
    "        \n",
    "        # graph embedding\n",
    "        g = Graph(list(nodes.keys()), list(edges.keys()))\n",
    "        g.insert_node_features(n)\n",
    "        g.insert_edge_features(e, edges_type)\n",
    "        \n",
    "        # first RGCN layer\n",
    "        h = self.RGCN1(g)\n",
    "        h = F.relu(h)\n",
    "        \n",
    "        # GAT layer\n",
    "        h = self.GAT(h, g.sparse_adj, e)\n",
    "        h = F.relu(h)\n",
    "        \n",
    "        # graph embedding\n",
    "        g = Graph(list(nodes.keys()), list(edges.keys()))\n",
    "        g.insert_node_features(h)\n",
    "        g.insert_edge_features(e, edges_type)\n",
    "        \n",
    "        # second RGCN layer\n",
    "        h = self.RGCN2(g)\n",
    "        h = F.relu(h)\n",
    "        \n",
    "        # decoding\n",
    "        out = self.n_dec(h)\n",
    "        out = self.max_action*torch.tanh(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, node_dim=4, edge_dim=2, action_dim=1, max_action=5, aggr_func='mean'):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        # node encoder\n",
    "        self.n_enc = nn.Linear(node_dim+action_dim, 64)\n",
    "        # edge encoder\n",
    "        self.e_enc = nn.Linear(edge_dim, 32)\n",
    "        \n",
    "        # first RGCN layer\n",
    "        self.RGCN1 = RGCNLayer(96, 64, 2)\n",
    "        # GAT layer\n",
    "        self.GAT = gnn.GATConv(64, 64, add_self_loops=False, edge_dim=32)\n",
    "        # second RGCN layer\n",
    "        self.RGCN2 = RGCNLayer(96, 64, 2)\n",
    "        \n",
    "        # node decoder\n",
    "        self.n_dec = nn.Linear(64, 1)\n",
    "        \n",
    "        self.max_action = max_action\n",
    "        self.aggr_func = aggr_func\n",
    "        \n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, nodes, edges, edges_type, actions):\n",
    "        n_feat = list(nodes.values())\n",
    "        n_feat = torch.as_tensor(n_feat, dtype=torch.float32, device=device)\n",
    "        e_feat = list(edges.values())\n",
    "        e_feat = torch.as_tensor(e_feat, dtype=torch.float32, device=device)\n",
    "        \n",
    "        # node encoding\n",
    "        if n_feat.size()[0] == 0:\n",
    "            n = n_feat\n",
    "        else:\n",
    "            n = torch.cat((n_feat,actions), 1)\n",
    "            n = self.n_enc(n) # n should be num_nodes*64\n",
    "            n = F.relu(n)\n",
    "        \n",
    "        # edge encoding\n",
    "        if e_feat.size()[0] == 0:\n",
    "            e = e_feat\n",
    "        else:\n",
    "            e = self.e_enc(e_feat) # e should be num_edges*32\n",
    "            e = F.relu(e)\n",
    "        \n",
    "        # graph embedding\n",
    "        g = Graph(list(nodes.keys()), list(edges.keys()))\n",
    "        g.insert_node_features(n)\n",
    "        g.insert_edge_features(e, edges_type)\n",
    "        \n",
    "        # first RGCN layer\n",
    "        h = self.RGCN1(g)\n",
    "        h = F.relu(h)\n",
    "        \n",
    "        # GAT layer\n",
    "        h = self.GAT(h, g.sparse_adj, e)\n",
    "        h = F.relu(h)\n",
    "\n",
    "        # graph embedding\n",
    "        g = Graph(list(nodes.keys()), list(edges.keys()))\n",
    "        g.insert_node_features(h)\n",
    "        g.insert_edge_features(e, edges_type)\n",
    "        \n",
    "        # second RGCN layer\n",
    "        h = self.RGCN2(g)\n",
    "        h = F.relu(h)\n",
    "\n",
    "        # decoding\n",
    "        if self.aggr_func == 'mean':\n",
    "            if g.num_nodes() > 0:\n",
    "                h = torch.sum(h, dim=0)/g.num_nodes()\n",
    "            else:\n",
    "                h = torch.sum(h, dim=0)\n",
    "        out = self.n_dec(h)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccfab24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, size):\n",
    "        \n",
    "        self.size = size\n",
    "        self.buffer = []\n",
    "        self.index = 0\n",
    "        self.length = 0\n",
    "        \n",
    "    def add(self, nodes, edges, edges_type, action, reward, nodes_, edges_, edges_type_, done):\n",
    "        \n",
    "        data = (nodes, edges, edges_type, action, reward, nodes_, edges_, edges_type_, done)\n",
    "        \n",
    "        if self.index >= len(self.buffer):\n",
    "            self.buffer.append(data)\n",
    "        else:\n",
    "            self.buffer[self.index] = data\n",
    "            \n",
    "        self.index = (self.index + 1) % self.size\n",
    "        \n",
    "        self.length = min(self.length + 1, self.size)\n",
    "        \n",
    "    def sample(self, batch_size, n_steps=1):\n",
    "        \n",
    "        samples = {'weights': np.ones(shape=batch_size, dtype=np.float32),\n",
    "                   'indexes': np.random.choice(self.length - n_steps + 1, batch_size, replace=False)}\n",
    "        \n",
    "        sample_data = []\n",
    "        if n_steps == 1:\n",
    "            for i in samples['indexes']:\n",
    "                data_i = self.buffer[i]\n",
    "                sample_data.append(data_i)\n",
    "        else:\n",
    "            for i in samples['indexes']:\n",
    "                data_i = self.buffer[i: i + n_steps]\n",
    "                sample_data.append(data_i)\n",
    "                \n",
    "        return samples, sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fed0e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "\n",
    "class AIM():\n",
    "    \n",
    "    def __init__(self, actor_model, actor_optimizer, critic_model_1, critic_optimizer_1,\n",
    "                 critic_model_2, critic_optimizer_2, explore_noise, warmup, replay_buffer,\n",
    "                 batch_size, update_interval, update_interval_actor, target_update_interval,\n",
    "                 soft_update_tau, n_steps, gamma, model_name, evaluate):\n",
    "        \n",
    "        self.actor_model = actor_model\n",
    "        self.actor_optimizer = actor_optimizer\n",
    "        self.critic_model_1 = critic_model_1\n",
    "        self.critic_optimizer_1 = critic_optimizer_1\n",
    "        self.critic_model_2 = critic_model_2\n",
    "        self.critic_optimizer_2 = critic_optimizer_2\n",
    "        \n",
    "        self.explore_noise = explore_noise\n",
    "        self.warmup = warmup\n",
    "        self.replay_buffer = replay_buffer\n",
    "        self.batch_size = batch_size\n",
    "        self.update_interval = update_interval\n",
    "        self.update_interval_actor = update_interval_actor\n",
    "        self.target_update_interval = target_update_interval\n",
    "        self.soft_update_tau = soft_update_tau\n",
    "        self.n_steps = n_steps\n",
    "        self.gamma = gamma\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.actor_model_target = copy.deepcopy(self.actor_model)\n",
    "        self.critic_model_target_1 = copy.deepcopy(self.critic_model_1)\n",
    "        self.critic_model_target_2 = copy.deepcopy(self.critic_model_2)\n",
    "        \n",
    "        self.time_counter = 0\n",
    "        \n",
    "        self.loss_record = collections.deque(maxlen=100)\n",
    "        \n",
    "        self.device = device\n",
    "        self.eval = evaluate\n",
    "        \n",
    "    def store_transition(self, nodes, edges, edges_type, action, reward, nodes_, edges_, edges_type_, done):\n",
    "        \n",
    "        self.replay_buffer.add(nodes, edges, edges_type, action, reward, nodes_, edges_, edges_type_, done)\n",
    "        \n",
    "    def sample_memory(self):\n",
    "        \n",
    "        samples, data_sample = self.replay_buffer.sample(self.batch_size, self.n_steps)\n",
    "        \n",
    "        return samples, data_sample\n",
    "    \n",
    "    def choose_action(self, nodes, edges, edges_type):\n",
    "        \n",
    "        if self.time_counter < self.warmup:\n",
    "            action = np.random.normal(scale=2,\n",
    "                                      size=(len(list(nodes.keys())),1))\n",
    "            action = torch.as_tensor(action, dtype=torch.float32).to(self.device)\n",
    "        else:\n",
    "            action = self.actor_model.forward(nodes, edges, edges_type)\n",
    "            if not self.eval:\n",
    "                noise = torch.as_tensor(np.random.normal(scale=self.explore_noise)).to(self.device)\n",
    "                action = action + noise\n",
    "   \n",
    "        action = torch.clamp(action, -self.actor_model.max_action, self.actor_model.max_action)\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def test_action(self, nodes, edges, edges_type):\n",
    "        \n",
    "        action = self.actor_model.forward(nodes, edges, edges_type)\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def loss_process(self, loss, weight):\n",
    "        \n",
    "        #weight = torch.as_tensor(weight, dtype=torch.float32).to(self.device) in teoria non serve più\n",
    "        #loss = torch.mean(loss*weight.detach()) in teoria non serve più\n",
    "        \n",
    "        return torch.mean(loss)\n",
    "    \n",
    "    def learn_onestep(self, info_batch, data_batch):\n",
    "        def safe(el):\n",
    "            return torch.as_tensor(el, dtype=torch.float32).detach()\n",
    "        actor_loss = []\n",
    "        critic_loss_1 = []\n",
    "        critic_loss_2 = []\n",
    "        self.critic_optimizer_1.zero_grad()\n",
    "        self.critic_optimizer_2.zero_grad()\n",
    "        \n",
    "        # SANITY CHECK\n",
    "        #tmp = [el.cpu().detach().numpy() for el in [self.critic_model_1.RGCN1.weight]]\n",
    "        \n",
    "        for elem in data_batch:\n",
    "            nodes, edges, edges_type, action, reward, nodes_, edges_, edges_type_, done = elem\n",
    "            action, reward, done = \\\n",
    "                [safe(el) for el in [action, reward, done]]\n",
    "            action = torch.as_tensor(action, dtype=torch.float32).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                action_target = self.actor_model_target.forward(nodes_, edges_, edges_type_)\n",
    "                action_target = action_target + \\\n",
    "                                torch.clamp(torch.as_tensor(np.random.normal(scale=0.1)), -0.5, 0.5)\n",
    "                action_target = torch.clamp(action_target,\n",
    "                                            -self.actor_model.max_action,\n",
    "                                            self.actor_model.max_action)\n",
    "\n",
    "                q1_next = self.critic_model_target_1.forward(nodes_, edges_, edges_type_, action_target)\n",
    "                q2_next = self.critic_model_target_2.forward(nodes_, edges_, edges_type_, action_target)\n",
    "                critic_value_next = torch.min(q1_next, q2_next)\n",
    "\n",
    "                critic_target = reward + self.gamma * critic_value_next * (1 - done)\n",
    "\n",
    "            q1 = self.critic_model_1.forward(nodes, edges, edges_type, action)\n",
    "            #q1 = q1.detach() in teoria non serve più\n",
    "            q2 = self.critic_model_2.forward(nodes, edges, edges_type, action)\n",
    "            #q2 = q2.detach() in teoria non serve più\n",
    "\n",
    "            q1_loss = F.smooth_l1_loss(critic_target, q1)\n",
    "            q2_loss = F.smooth_l1_loss(critic_target, q2)\n",
    "            critic_loss_1.append(q1_loss)\n",
    "            critic_loss_2.append(q2_loss)\n",
    "            \n",
    "        critic_loss_e_1 = torch.stack(critic_loss_1)\n",
    "        critic_loss_e_2 = torch.stack(critic_loss_2)\n",
    "        critic_loss_total_1 = self.loss_process(critic_loss_e_1, info_batch['weights'])\n",
    "        critic_loss_total_2 = self.loss_process(critic_loss_e_2, info_batch['weights'])\n",
    "        \n",
    "        (critic_loss_total_1 + critic_loss_total_2).backward(retain_graph=True)\n",
    "        self.critic_optimizer_1.step()\n",
    "        self.critic_optimizer_2.step()\n",
    "        \n",
    "        # SANITY CHECK\n",
    "        #diff = np.mean([((t1-t2) ** 2).mean() for t1, t2 in zip(tmp, [el.cpu().detach().numpy() \\\n",
    "        #                            for el in [self.critic_model_1.RGCN1.weight]])])\n",
    "        #print(f\"diff : {diff}\")\n",
    "        #print(self.critic_model_1.RGCN1.weight)\n",
    "    \n",
    "        if self.time_counter % self.update_interval_actor != 0:\n",
    "            return\n",
    "        \n",
    "        for elem in data_batch:\n",
    "            nodes, edges, edges_type, action, reward, nodes_, edges_, edges_type_, done = elem\n",
    "            \n",
    "            mu = self.actor_model.forward(nodes, edges, edges_type)\n",
    "            actor_loss_sample = -1 * self.critic_model_1.forward(nodes, edges, edges_type, mu)\n",
    "            actor_loss_s = actor_loss_sample.mean()\n",
    "            actor_loss.append(actor_loss_s)\n",
    "            \n",
    "        actor_loss_e = torch.stack(actor_loss)\n",
    "        actor_loss_total = self.loss_process(actor_loss_e, info_batch['weights'])\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss_total.backward(retain_graph=True)\n",
    "        self.actor_optimizer.step()\n",
    "        \n",
    "        self.loss_record.append(float((critic_loss_total_1 +\n",
    "                                       critic_loss_total_2 +\n",
    "                                       actor_loss_total).detach().cpu().numpy()))\n",
    "        \n",
    "    def synchronize_target(self):\n",
    "\n",
    "        assert 0.0 < self.soft_update_tau <= 1.0\n",
    "\n",
    "        for target_param, source_param in zip(self.critic_model_target_1.parameters(),\n",
    "                                              self.critic_model_1.parameters()):\n",
    "            target_param.data.copy_((1 - self.soft_update_tau) *\n",
    "                                target_param.data + self.soft_update_tau * source_param.data)\n",
    "\n",
    "        for target_param, source_param in zip(self.critic_model_target_2.parameters(),\n",
    "                                              self.critic_model_2.parameters()):\n",
    "            target_param.data.copy_((1 - self.soft_update_tau) *\n",
    "                                target_param.data + self.soft_update_tau * source_param.data)\n",
    "\n",
    "        for target_param, source_param in zip(self.actor_model_target.parameters(),\n",
    "                                              self.actor_model.parameters()):\n",
    "            target_param.data.copy_((1 - self.soft_update_tau) *\n",
    "                                target_param.data + self.soft_update_tau * source_param.data)\n",
    "\n",
    "    def learn(self):\n",
    "\n",
    "        if self.time_counter <= self.warmup or \\\n",
    "            (self.time_counter % self.update_interval != 0):\n",
    "            self.time_counter += 1\n",
    "            return\n",
    "\n",
    "        samples, data_sample = self.sample_memory()\n",
    "\n",
    "        if self.n_steps == 1: # FOR THE MOMENT ALWAYS THE CASE FOR US\n",
    "            self.learn_onestep(samples, data_sample)\n",
    "\n",
    "        if self.time_counter % self.target_update_interval == 0:\n",
    "            self.synchronize_target()\n",
    "\n",
    "        self.time_counter += 1\n",
    "\n",
    "    def get_statistics(self):\n",
    "\n",
    "        loss_statistics = np.mean(self.loss_record) if self.loss_record else np.nan\n",
    "        return [loss_statistics]\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        \"\"\"\n",
    "           <Model saving function>\n",
    "           Used to save the trained model\n",
    "        \"\"\"\n",
    "        save_path_actor = save_path + \"/\" + self.model_name + \"_actor\" + \".pt\"\n",
    "        save_path_critic_1 = save_path + \"/\" + self.model_name + \"_critic_1\" + \".pt\"\n",
    "        save_path_critic_2 = save_path + \"/\" + self.model_name + \"_critic_2\" + \".pt\"\n",
    "        torch.save(self.actor_model, save_path_actor)\n",
    "        torch.save(self.critic_model_1, save_path_critic_1)\n",
    "        torch.save(self.critic_model_2, save_path_critic_2)\n",
    "\n",
    "    def load_model(self, load_path):\n",
    "        \"\"\"\n",
    "           <model reading function>\n",
    "           Used to read the trained model\n",
    "        \"\"\"\n",
    "        load_path_actor = load_path + \"/\" + self.model_name + \"_actor\" + \".pt\"\n",
    "        load_path_critic_1 = load_path + \"/\" + self.model_name + \"_critic_1\" + \".pt\"\n",
    "        load_path_critic_2 = load_path + \"/\" + self.model_name + \"_critic_2\" + \".pt\"\n",
    "        self.actor_model = torch.load(load_path_actor)\n",
    "        self.critic_model_1 = torch.load(load_path_critic_1)\n",
    "        self.critic_model_2 = torch.load(load_path_critic_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cbc6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.utils.registry import make_create_env\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(aim):\n",
    "    flow_params = dict(\n",
    "    exp_tag='test_network',\n",
    "    env_name=myEnv,\n",
    "    network=IntersectionNetwork,\n",
    "    simulator='traci',\n",
    "    sim=sim_params,\n",
    "    env=env_params,\n",
    "    net=net_params,\n",
    "    veh=vehicles,\n",
    "    initial=initial_config,\n",
    "    )\n",
    "\n",
    "    # number of time steps\n",
    "    flow_params['env'].horizon = 1000\n",
    "\n",
    "    # Get the env name and a creator for the environment.\n",
    "    create_env, _ = make_create_env(flow_params)\n",
    "\n",
    "    # Create the environment.\n",
    "    env = create_env()\n",
    "    num_steps = env.env_params.horizon\n",
    "    \n",
    "    ret = 0\n",
    "    state = env.reset()\n",
    "    \n",
    "    veh_ids = env.k.vehicle.get_ids()\n",
    "    edges, edges_type = compute_edges(env, state)\n",
    "    nodes = {}\n",
    "    for node in list(state.keys()):\n",
    "        nodes[node] = state[node][:4]\n",
    "    aim.eval = True\n",
    "    eval_steps = 0\n",
    "    \n",
    "    for j in range(num_steps):\n",
    "        \n",
    "        actions = aim.choose_action(nodes, edges, edges_type)\n",
    "        \n",
    "        state_, reward, done, _ = env.step(rl_actions=actions.cpu().detach().numpy())\n",
    "\n",
    "        veh_ids = env.k.vehicle.get_ids()\n",
    "        edges_, edges_type_ = compute_edges(env, state_)\n",
    "        nodes_ = {}\n",
    "        for node in list(state_.keys()):\n",
    "            nodes_[node] = state_[node][:4]\n",
    "        \n",
    "        proximity_reward = compute_rp(edges)\n",
    "        w_p = 0.2\n",
    "        reward += proximity_reward*w_p\n",
    "        \n",
    "        nodes = nodes_\n",
    "        edges = edges_\n",
    "        edges_type = edges_type_\n",
    "        \n",
    "        ret += reward\n",
    "        eval_steps += 1\n",
    "        \n",
    "        if done:\n",
    "            #print('CRASH')\n",
    "            break\n",
    "    \n",
    "    # Store the information from the run in info_dict.\n",
    "    outflow = env.k.vehicle.get_outflow_rate(int(eval_steps))\n",
    "\n",
    "    print(\"Return: {0}\".format(ret/eval_steps))\n",
    "    print(\"Duration of the episode: {0}\".format(eval_steps))\n",
    "    print(\"Outflow: {0}\".format(outflow))\n",
    "    print('-----------------------')\n",
    "    env.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1f080d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Speed of turning connection 't_c_0->c_l_0' reduced by 23.98 due to turning radius of 6.59 (length=7.58, angle=90.00).\n",
      "Warning: Speed of turning connection 't_c_0->c_r_0' reduced by 22.58 due to turning radius of 10.02 (length=12.07, angle=90.00).\n",
      "Warning: Speed of turning connection 'r_c_0->c_t_0' reduced by 23.98 due to turning radius of 6.59 (length=7.58, angle=90.00).\n",
      "Warning: Speed of turning connection 'r_c_0->c_b_0' reduced by 22.58 due to turning radius of 10.02 (length=12.07, angle=90.00).\n",
      "Warning: Speed of turning connection 'b_c_0->c_r_0' reduced by 23.98 due to turning radius of 6.59 (length=7.58, angle=90.00).\n",
      "Warning: 8 total messages of type: Speed of % connection '%' reduced by % due to turning radius of % (length=%, angle=%).\n",
      "Warning: Speed of turning connection 't_c_0->c_l_0' reduced by 23.98 due to turning radius of 6.59 (length=7.58, angle=90.00).\n",
      "Warning: Speed of turning connection 't_c_0->c_r_0' reduced by 22.58 due to turning radius of 10.02 (length=12.07, angle=90.00).\n",
      "Warning: Speed of turning connection 'r_c_0->c_t_0' reduced by 23.98 due to turning radius of 6.59 (length=7.58, angle=90.00).\n",
      "Warning: Speed of turning connection 'r_c_0->c_b_0' reduced by 22.58 due to turning radius of 10.02 (length=12.07, angle=90.00).\n",
      "Warning: Speed of turning connection 'b_c_0->c_r_0' reduced by 23.98 due to turning radius of 6.59 (length=7.58, angle=90.00).\n",
      "Warning: 8 total messages of type: Speed of % connection '%' reduced by % due to turning radius of % (length=%, angle=%).\n",
      "/home/matteo/anaconda3/envs/flow/lib/python3.7/site-packages/ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/matteo/.local/bin/sumo-gui\", line 8, in <module>\n",
      "    sys.exit(sumo_gui())\n",
      "  File \"/home/matteo/.local/lib/python3.8/site-packages/sumo/__init__.py\", line 29, in <lambda>\n",
      "    return lambda: sys.exit(subprocess.call([os.path.join(SUMO_HOME, 'bin', app)] + sys.argv[1:], env=ENV))\n",
      "  File \"/usr/lib/python3.8/subprocess.py\", line 342, in call\n",
      "    return p.wait(timeout=timeout)\n",
      "  File \"/usr/lib/python3.8/subprocess.py\", line 1083, in wait\n",
      "    return self._wait(timeout=timeout)\n",
      "  File \"/usr/lib/python3.8/subprocess.py\", line 1806, in _wait\n",
      "    (pid, sts) = self._try_wait(0)\n",
      "  File \"/usr/lib/python3.8/subprocess.py\", line 1764, in _try_wait\n",
      "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8792/2777252690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mstate_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mveh_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvehicle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/Thesis/Codice/flow/flow/envs/base.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, rl_actions)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;31m# advance the simulation in the simulator by one step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;31m# store new observations in the vehicles and traffic lights class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/Thesis/Codice/flow/flow/core/kernel/simulation/traci.py\u001b[0m in \u001b[0;36msimulation_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimulation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;34m\"\"\"See parent class.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulationStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flow/lib/python3.7/site-packages/traci/connection.py\u001b[0m in \u001b[0;36msimulationStep\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMD_SIMSTEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_string\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!BBd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMD_SIMSTEP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendExact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msubscriptionResults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subscriptionMapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0msubscriptionResults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flow/lib/python3.7/site-packages/traci/connection.py\u001b[0m in \u001b[0;36m_sendExact\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recvExact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flow/lib/python3.7/site-packages/traci/connection.py\u001b[0m in \u001b[0;36m_recvExact\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from flow.utils.registry import make_create_env\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "flow_params = dict(\n",
    "    exp_tag='test_network',\n",
    "    env_name=myEnv,\n",
    "    network=IntersectionNetwork,\n",
    "    simulator='traci',\n",
    "    sim=sim_params,\n",
    "    env=env_params,\n",
    "    net=net_params,\n",
    "    veh=vehicles,\n",
    "    initial=initial_config,\n",
    ")\n",
    "\n",
    "# number of time steps\n",
    "flow_params['env'].horizon = 1000\n",
    "\n",
    "# Get the env name and a creator for the environment.\n",
    "create_env, _ = make_create_env(flow_params)\n",
    "\n",
    "# Create the environment.\n",
    "env = create_env()\n",
    "\n",
    "logging.info(\" Starting experiment {} at {}\".format(\n",
    "    env.network.name, str(datetime.utcnow())))\n",
    "\n",
    "logging.info(\"Initializing environment.\")\n",
    "\n",
    "finished = False\n",
    "\n",
    "num_steps = env.env_params.horizon\n",
    "\n",
    "# raise an error if convert_to_csv is set to True but no emission\n",
    "# file will be generated, to avoid getting an error at the end of the\n",
    "# simulation\n",
    "convert_to_csv = False\n",
    "if convert_to_csv and env.sim_params.emission_path is None:\n",
    "    raise ValueError(\n",
    "        'The experiment was run with convert_to_csv set '\n",
    "        'to True, but no emission file will be generated. If you wish '\n",
    "        'to generate an emission file, you should set the parameter '\n",
    "        'emission_path in the simulation parameters (SumoParams or '\n",
    "        'AimsunParams) to the path of the folder where emissions '\n",
    "        'output should be generated. If you do not wish to generate '\n",
    "        'emissions, set the convert_to_csv parameter to False.')\n",
    "\n",
    "# used to store\n",
    "outflows = []\n",
    "returns = []\n",
    "\n",
    "# time profiling information\n",
    "t = time.time()\n",
    "times = []\n",
    "\n",
    "# RL agent initialization - inizio\n",
    "actor = Actor()\n",
    "critic_1 = Critic()\n",
    "critic_2 = Critic()\n",
    "\n",
    "lr = 3e-4\n",
    "actor_optimizer = torch.optim.Adam(actor.parameters(), lr=lr)\n",
    "critic_optimizer_1 = torch.optim.Adam(critic_1.parameters(), lr=lr)\n",
    "critic_optimizer_2 = torch.optim.Adam(critic_2.parameters(), lr=lr)\n",
    "\n",
    "explore_noise = 0.1\n",
    "\n",
    "replay_buffer = ReplayBuffer(size=10**6)\n",
    "\n",
    "gamma = 0.99\n",
    "\n",
    "warmup = 25000\n",
    "#warmup = 25000 # now\n",
    "# RL agent initialization - fine\n",
    "\n",
    "aim = AIM(actor,\n",
    "          actor_optimizer,\n",
    "          critic_1,\n",
    "          critic_optimizer_1,\n",
    "          critic_2,\n",
    "          critic_optimizer_2,\n",
    "          explore_noise,\n",
    "          warmup,\n",
    "          replay_buffer,\n",
    "          # batch_size=32, before\n",
    "          batch_size=256, # now\n",
    "          #update_interval=100,\n",
    "          update_interval=1, # now\n",
    "          #update_interval_actor=500, before\n",
    "          update_interval_actor=2, # now\n",
    "          #target_update_interval=5000, before\n",
    "          target_update_interval=2, # now\n",
    "          soft_update_tau=0.005,\n",
    "          n_steps=1,\n",
    "          gamma=gamma,\n",
    "          model_name='AIM_model',\n",
    "          evaluate=False)\n",
    "\n",
    "st = 0\n",
    "\n",
    "while not finished:\n",
    "    ep_steps = 0\n",
    "    ret = 0\n",
    "    state = env.reset()\n",
    "    \n",
    "    veh_ids = env.k.vehicle.get_ids()\n",
    "    edges, edges_type = compute_edges(env, state)\n",
    "    nodes = {}\n",
    "    for node in list(state.keys()):\n",
    "        nodes[node] = state[node][:4]\n",
    "    \n",
    "    for j in range(num_steps):\n",
    "        \n",
    "        actions = aim.choose_action(nodes, edges, edges_type)\n",
    "\n",
    "        t0 = time.time()\n",
    "        \n",
    "        state_, reward, done, _ = env.step(rl_actions=actions.cpu().detach().numpy())\n",
    "\n",
    "        veh_ids = env.k.vehicle.get_ids()\n",
    "        edges_, edges_type_ = compute_edges(env, state_)\n",
    "        nodes_ = {}\n",
    "        for node in list(state_.keys()):\n",
    "            nodes_[node] = state_[node][:4]\n",
    "        \n",
    "        Rp = compute_rp(edges)\n",
    "        w_p = 0.2\n",
    "        reward += Rp*w_p\n",
    "\n",
    "        if nodes != {}:\n",
    "            aim.store_transition(nodes, edges, edges_type, actions, reward, nodes_, edges_, edges_type_, done)\n",
    "        aim.learn()\n",
    "        \n",
    "        nodes = nodes_\n",
    "        edges = edges_\n",
    "        edges_type = edges_type_\n",
    "        \n",
    "        t1 = time.time()\n",
    "        times.append(1 / (t1 - t0))\n",
    "        \n",
    "        ret += reward\n",
    "        st += 1\n",
    "        ep_steps += 1\n",
    "        \n",
    "        if done:\n",
    "            #print('CRASH')\n",
    "            break\n",
    "        if st == 500000:\n",
    "            finished = True\n",
    "            break\n",
    "        if st % 5000 == 0:\n",
    "            print('EVALUATION RUN')\n",
    "            evaluate(aim)\n",
    "            print('END EVALUATION')\n",
    "            break\n",
    "    \n",
    "    # Store the information from the run in info_dict.\n",
    "    outflow = env.k.vehicle.get_outflow_rate(int(ep_steps))\n",
    "    outflows.append(outflow)\n",
    "    returns.append(ret)\n",
    "\n",
    "    print(\"Weighted return: {0}\".format(ret/ep_steps))\n",
    "    print(\"Duration of the episode: {0}\".format(ep_steps))\n",
    "    print(\"Outflow: {0}\".format(outflow))\n",
    "    print('-----------------------')\n",
    "    \n",
    "    aim.save_model('../TrainedModels/TD3')\n",
    "\n",
    "    # Save emission data at the end of every rollout. This is skipped\n",
    "    # by the internal method if no emission path was specified.\n",
    "    if env.simulator == \"traci\":\n",
    "        env.k.simulation.save_emission(run_id=i)\n",
    "\n",
    "# Print the averages/std for all variables in the info_dict.\n",
    "print(\"Total time:\", time.time() - t)\n",
    "print(\"steps/second:\", np.mean(times))\n",
    "env.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f29612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:flow] *",
   "language": "python",
   "name": "conda-env-flow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
