{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b79f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from flow.core.params import InitialConfig\n",
    "from flow.core.params import TrafficLightParams\n",
    "from flow.networks.base import Network\n",
    "\n",
    "ADDITIONAL_NET_PARAMS = {\n",
    "    # radius of the intersection\n",
    "    \"radius_intersection\": 15,\n",
    "    # number of lanes\n",
    "    \"lanes\": 3,\n",
    "    # speed limit for all edges\n",
    "    \"speed_limit\": 13.9,\n",
    "    # resolution of the curved portions\n",
    "    \"resolution\": 40\n",
    "}\n",
    "\n",
    "class IntersectionNetwork(Network):\n",
    "    \"\"\" Requires from net_params:\n",
    "\n",
    "    * **radius_intersection** : radius of the intersection\n",
    "    * **resolution** : number of nodes resolution in the circular portions\n",
    "    * **lanes** : number of lanes in the network\n",
    "    * **speed** : max speed of vehicles in the network\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    >>> from flow.core.params import NetParams\n",
    "    >>> from flow.core.params import VehicleParams\n",
    "    >>> from flow.core.params import InitialConfig\n",
    "    >>> from road_network import IntersectionNetwork\n",
    "    >>>\n",
    "    >>> network = IntersectionNetwork(\n",
    "    >>>     name='intersection',\n",
    "    >>>     vehicles=VehicleParams(),\n",
    "    >>>     net_params=NetParams(\n",
    "    >>>         additional_params={\n",
    "    >>>             'radius_intersection': 15,\n",
    "    >>>             'lanes': 3,\n",
    "    >>>             'speed_limit': 13.9,\n",
    "    >>>             'resolution': 40\n",
    "    >>>         },\n",
    "    >>>     )\n",
    "    >>> )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 name,\n",
    "                 vehicles,\n",
    "                 net_params,\n",
    "                 initial_config=InitialConfig(),\n",
    "                 traffic_lights=TrafficLightParams()):\n",
    "\n",
    "        for p in ADDITIONAL_NET_PARAMS.keys():\n",
    "            if p not in net_params.additional_params:\n",
    "                raise KeyError('Network parameter \"{}\" not supplied'.format(p))\n",
    "\n",
    "        self.intersection_len = 100\n",
    "\n",
    "        super().__init__(name, vehicles, net_params, initial_config,\n",
    "                         traffic_lights)\n",
    "\n",
    "    def specify_nodes(self, net_params):\n",
    "        \"\"\"See parent class.\"\"\"\n",
    "        r = net_params.additional_params[\"radius_intersection\"]\n",
    "\n",
    "        nodes = [{\n",
    "            \"id\": \"center\",\n",
    "            \"x\": 0,\n",
    "            \"y\": 0,\n",
    "            \"radius\": r,\n",
    "            \"type\": \"priority\"\n",
    "        }, {\n",
    "            \"id\": \"right\",\n",
    "            \"x\": self.intersection_len,\n",
    "            \"y\": 0,\n",
    "            \"type\": \"priority\"\n",
    "        }, {\n",
    "            \"id\": \"top\",\n",
    "            \"x\": 0,\n",
    "            \"y\": self.intersection_len,\n",
    "            \"type\": \"priority\"\n",
    "        }, {\n",
    "            \"id\": \"left\",\n",
    "            \"x\": -self.intersection_len,\n",
    "            \"y\": 0,\n",
    "            \"type\": \"priority\"\n",
    "        }, {\n",
    "            \"id\": \"bottom\",\n",
    "            \"x\": 0,\n",
    "            \"y\": -self.intersection_len,\n",
    "            \"type\": \"priority\"\n",
    "        }]\n",
    "\n",
    "        return nodes\n",
    "\n",
    "    def specify_edges(self, net_params):\n",
    "        \"\"\"See parent class.\"\"\"\n",
    "\n",
    "        # intersection edges\n",
    "        edges = [{\n",
    "            \"id\": \"b_c\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": \"78\",\n",
    "            \"from\": \"bottom\",\n",
    "            \"to\": \"center\",\n",
    "            \"length\": self.intersection_len\n",
    "        }, {\n",
    "            \"id\": \"c_t\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": 78,\n",
    "            \"from\": \"center\",\n",
    "            \"to\": \"top\",\n",
    "            \"length\": self.intersection_len\n",
    "        }, {\n",
    "            \"id\": \"r_c\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": 78,\n",
    "            \"from\": \"right\",\n",
    "            \"to\": \"center\",\n",
    "            \"length\": self.intersection_len\n",
    "        }, {\n",
    "            \"id\": \"c_l\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": 46,\n",
    "            \"from\": \"center\",\n",
    "            \"to\": \"left\",\n",
    "            \"length\": self.intersection_len\n",
    "        }, {\n",
    "            \"id\": \"t_c\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": 78,\n",
    "            \"from\": \"top\",\n",
    "            \"to\": \"center\",\n",
    "            \"length\": self.intersection_len\n",
    "        }, {\n",
    "            \"id\": \"c_r\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": 46,\n",
    "            \"from\": \"center\",\n",
    "            \"to\": \"right\",\n",
    "            \"length\": self.intersection_len\n",
    "        }, {\n",
    "            \"id\": \"l_c\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": 78,\n",
    "            \"from\": \"left\",\n",
    "            \"to\": \"center\",\n",
    "            \"length\": self.intersection_len\n",
    "        }, {\n",
    "            \"id\": \"c_b\",\n",
    "            \"type\": \"edgeType\",\n",
    "            #\"priority\": \"78\",\n",
    "            \"from\": \"center\",\n",
    "            \"to\": \"bottom\",\n",
    "            \"length\": self.intersection_len\n",
    "        }]\n",
    "\n",
    "        return edges\n",
    "\n",
    "    def specify_types(self, net_params):\n",
    "        \"\"\"See parent class.\"\"\"\n",
    "        lanes = net_params.additional_params[\"lanes\"]\n",
    "        speed_limit = net_params.additional_params[\"speed_limit\"]\n",
    "        types = [{\n",
    "            \"id\": \"edgeType\",\n",
    "            \"numLanes\": lanes,\n",
    "            \"speed\": speed_limit\n",
    "        }]\n",
    "\n",
    "        return types\n",
    "\n",
    "    def specify_connections(self, net_params):\n",
    "        \"\"\"See parent class.\"\"\"\n",
    "        lanes = net_params.additional_params[\"lanes\"]\n",
    "        conn_dict = {}\n",
    "        conn = []\n",
    "        conn += [{\"from\": \"b_c\",\n",
    "                  \"to\": \"c_t\",\n",
    "                  \"fromLane\": str(1),\n",
    "                  \"toLane\": str(1)}]\n",
    "        conn += [{\"from\": \"b_c\",\n",
    "                  \"to\": \"c_r\",\n",
    "                  \"fromLane\": str(0),\n",
    "                  \"toLane\": str(0)}]\n",
    "        conn += [{\"from\": \"b_c\",\n",
    "                  \"to\": \"c_l\",\n",
    "                  \"fromLane\": str(2),\n",
    "                  \"toLane\": str(2)}]\n",
    "        conn += [{\"from\": \"t_c\",\n",
    "                  \"to\": \"c_b\",\n",
    "                  \"fromLane\": str(1),\n",
    "                  \"toLane\": str(1)}]\n",
    "        conn += [{\"from\": \"t_c\",\n",
    "                  \"to\": \"c_l\",\n",
    "                  \"fromLane\": str(0),\n",
    "                  \"toLane\": str(0)}]\n",
    "        conn += [{\"from\": \"t_c\",\n",
    "                  \"to\": \"c_r\",\n",
    "                  \"fromLane\": str(2),\n",
    "                  \"toLane\": str(2)}]\n",
    "        conn += [{\"from\": \"r_c\",\n",
    "                  \"to\": \"c_l\",\n",
    "                  \"fromLane\": str(1),\n",
    "                  \"toLane\": str(1)}]\n",
    "        conn += [{\"from\": \"r_c\",\n",
    "                  \"to\": \"c_t\",\n",
    "                  \"fromLane\": str(0),\n",
    "                  \"toLane\": str(0)}]\n",
    "        conn += [{\"from\": \"r_c\",\n",
    "                  \"to\": \"c_b\",\n",
    "                  \"fromLane\": str(2),\n",
    "                  \"toLane\": str(2)}]\n",
    "        conn += [{\"from\": \"l_c\",\n",
    "                  \"to\": \"c_r\",\n",
    "                  \"fromLane\": str(1),\n",
    "                  \"toLane\": str(1)}]\n",
    "        conn += [{\"from\": \"l_c\",\n",
    "                  \"to\": \"c_b\",\n",
    "                  \"fromLane\": str(0),\n",
    "                  \"toLane\": str(0)}]\n",
    "        conn += [{\"from\": \"l_c\",\n",
    "                  \"to\": \"c_t\",\n",
    "                  \"fromLane\": str(2),\n",
    "                  \"toLane\": str(2)}]\n",
    "\n",
    "        conn_dict[\"center\"] = conn\n",
    "        return conn_dict\n",
    "    \n",
    "    def specify_routes(self, net_params):\n",
    "        \"\"\"See parent class.\"\"\"\n",
    "        rts = {\n",
    "            \"r_c\":\n",
    "                [([\"r_c\", \"c_l\"], 1/3), ([\"r_c\", \"c_t\"], 1/3),\n",
    "                    ([\"r_c\", \"c_b\"], 1/3)],\n",
    "            \"b_c\":\n",
    "                [([\"b_c\", \"c_l\"], 1/3), ([\"b_c\", \"c_t\"], 1/3),\n",
    "                    ([\"b_c\", \"c_r\"], 1/3)],\n",
    "            \"t_c\":\n",
    "                [([\"t_c\", \"c_b\"], 1/3), ([\"t_c\", \"c_l\"], 1/3),\n",
    "                    ([\"t_c\", \"c_r\"], 1/3)],\n",
    "            \"l_c\":\n",
    "                [([\"l_c\", \"c_r\"], 1/3), ([\"l_c\", \"c_t\"], 1/3),\n",
    "                    ([\"l_c\", \"c_b\"], 1/3)],\n",
    "            \"c_r\":\n",
    "                [\"c_r\"],\n",
    "            \"c_l\":\n",
    "                [\"c_l\"],\n",
    "            \"c_t\":\n",
    "                [\"c_t\"],\n",
    "            \"c_b\":\n",
    "                [\"c_b\"],\n",
    "            \"human_0\":\n",
    "                [\"r_c\", \"c_t\"],\n",
    "            \"human_1\":\n",
    "                [\"t_c\", \"c_b\"],\n",
    "            \"human_2\":\n",
    "                [\"l_c\", \"c_t\"]\n",
    "            }\n",
    "\n",
    "        return rts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984fbcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_vehicles(state):\n",
    "    distances = {}\n",
    "    ordered_vehicles = []\n",
    "    \n",
    "    for veh in list(state.keys()):\n",
    "        perturbation = 1e-10*np.random.randn()\n",
    "        dist = np.sqrt(state[veh][0]**2 + state[veh][1]**2) + perturbation\n",
    "        distances[dist] = veh\n",
    "    \n",
    "    for _ in list(state.keys()):\n",
    "        min_dist = min(list(distances.keys()))\n",
    "        ordered_vehicles.append(distances[min_dist])\n",
    "        distances.pop(min_dist)\n",
    "        \n",
    "    return ordered_vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24bd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.envs.base_gpt import Env\n",
    "import torch\n",
    "from gym.spaces.box import Box\n",
    "from gym.spaces import MultiBinary\n",
    "\n",
    "#import numpy as np\n",
    "\n",
    "lanes = { 0: [0.0, 0.0, 1.0],\n",
    "          1: [0.0, 1.0, 0.0],\n",
    "          2: [1.0, 0.0, 0.0]\n",
    "        }\n",
    "ways = { ('t_c', 'c_l'): [1.0, 0.0, 0.0], ('t_c', 'c_b'): [0.0, 1.0, 0.0], ('t_c', 'c_r'): [0.0, 0.0, 1.0],\n",
    "         ('r_c', 'c_t'): [1.0, 0.0, 0.0], ('r_c', 'c_l'): [0.0, 1.0, 0.0], ('r_c', 'c_b'): [0.0, 0.0, 1.0],\n",
    "         ('b_c', 'c_r'): [1.0, 0.0, 0.0], ('b_c', 'c_t'): [0.0, 1.0, 0.0], ('b_c', 'c_l'): [0.0, 0.0, 1.0],\n",
    "         ('l_c', 'c_b'): [1.0, 0.0, 0.0], ('l_c', 'c_r'): [0.0, 1.0, 0.0], ('l_c', 'c_t'): [0.0, 0.0, 1.0]\n",
    "       }\n",
    "queues = { 't_c': [1.0, 0.0, 0.0, 0.0],\n",
    "           'b_c': [0.0, 1.0, 0.0, 0.0],\n",
    "           'r_c': [0.0, 0.0, 1.0, 0.0],\n",
    "           'l_c': [0.0, 0.0, 0.0, 1.0],\n",
    "         }\n",
    "\n",
    "ADDITIONAL_ENV_PARAMS = {\n",
    "    # maximum velocity for autonomous vehicles, in m/s\n",
    "    'max_speed': 13.9,\n",
    "}\n",
    "\n",
    "\n",
    "class SpeedEnv(Env):\n",
    "    \"\"\"Fully observed velocity environment.\n",
    "\n",
    "    This environment used to train autonomous vehicles to improve traffic flows\n",
    "    when velocity actions are permitted by the rl agent.\n",
    "\n",
    "    Required from env_params:\n",
    "\n",
    "    * max_speed: maximum speed for autonomous vehicles, in m/s^2\n",
    "    * sort_vehicles: specifies whether vehicles are to be sorted by position\n",
    "      during a simulation step. If set to True, the environment parameter\n",
    "      self.sorted_ids will return a list of all vehicles sorted in accordance\n",
    "      with the environment\n",
    "\n",
    "    States\n",
    "        The state consists of (for each vehicle in the network):\n",
    "        - relative position to the center of the intersection on the x-axis\n",
    "        - relative position to the center of the intersection on the y-axis\n",
    "        - vehicle speed\n",
    "        - vehicle orientation angle\n",
    "        - lane of approach (one-hot)\n",
    "        - way the vehicle will follow (one-hot)\n",
    "        - intersection branch through which the vehicle is approaching (one-hot)\n",
    "\n",
    "    Actions\n",
    "        Actions are a list of speeds for each rl vehicle\n",
    "        \n",
    "    Rewards\n",
    "        The reward function is a summation of three terms (for each vehicle):\n",
    "        - -100 if there was a collision\n",
    "        - +100 if the intersection was crossed\n",
    "        - -timestep to encourage crossing as fast as possible\n",
    "        \n",
    "    Termination\n",
    "        A rollout is terminated if the time horizon is reached or if two\n",
    "        vehicles collide into one another.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env_params, sim_params, network, simulator='traci'):\n",
    "        for p in ADDITIONAL_ENV_PARAMS.keys():\n",
    "            if p not in env_params.additional_params:\n",
    "                raise KeyError(\n",
    "                    'Environment parameter \\'{}\\' not supplied'.format(p))\n",
    "        \n",
    "        super().__init__(env_params, sim_params, network, simulator)\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        \"\"\"See class definition.\"\"\"\n",
    "        num_vehicles = len(self.k.vehicle.get_ids())\n",
    "        return Box(\n",
    "            low=0,\n",
    "            high=self.env_params.additional_params['max_speed'],\n",
    "            shape=(num_vehicles, ),\n",
    "            dtype=np.float32)\n",
    "\n",
    "    @property\n",
    "    def observation_space(self):\n",
    "        \"\"\"See class definition.\"\"\"\n",
    "        vehs = len(self.k.vehicle.get_ids())\n",
    "        obs_space = Box(low=-1, high=1, shape=(vehs,14*vehs))\n",
    "            \n",
    "        return obs_space\n",
    "\n",
    "    def _apply_rl_actions(self, rl_actions, vehs):\n",
    "        \"\"\"See class definition.\"\"\"\n",
    "        self.k.vehicle.apply_velocity(vehs, rl_actions)\n",
    "\n",
    "    def compute_reward(self, vehs, **kwargs):\n",
    "        \"\"\"See class definition.\"\"\"\n",
    "        ids = self.k.vehicle.get_ids()\n",
    "        # collided_vehicles\n",
    "        coll_veh = self.k.simulation.collided_vehicles()\n",
    "        # successful_vehicles\n",
    "        succ_veh = self.k.simulation.successful_vehicles()\n",
    "        \n",
    "        rewards = torch.tensor([])\n",
    "        dones = torch.tensor([])\n",
    "        \n",
    "        for i in vehs:\n",
    "            if i in ids:\n",
    "                if i in coll_veh:\n",
    "                    reward = torch.tensor([-100.0])\n",
    "                    done = torch.tensor([1.0])\n",
    "                elif i in succ_veh:\n",
    "                    reward = torch.tensor([100.0])\n",
    "                    done = torch.tensor([1.0])\n",
    "                else:\n",
    "                    reward = torch.tensor([-0.25])\n",
    "                    done = torch.tensor([0.0])\n",
    "            else:\n",
    "                reward = torch.tensor([100.0])\n",
    "                done = torch.tensor([1.0])\n",
    "            \n",
    "            rewards = torch.cat((rewards, reward))\n",
    "            dones = torch.cat((dones, done))\n",
    "\n",
    "        return rewards, dones\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"See class definition.\"\"\"\n",
    "        \n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        ids = self.k.vehicle.get_ids()\n",
    "        state_dict = {}\n",
    "        \n",
    "        for q in ids:\n",
    "            obs = []\n",
    "            \n",
    "            # POSITION\n",
    "            pos = self.k.vehicle.get_2d_position(q)\n",
    "            obs.append(np.clip((pos[0]-100)/100, -1, 1))\n",
    "            obs.append(np.clip((pos[1]-100)/100, -1, 1))\n",
    "            \n",
    "            # VELOCITY\n",
    "            vel = np.clip((self.k.vehicle.get_speed(q) - 13.9/2)/(13.9/2), -1, 1)\n",
    "            obs.append(vel)\n",
    "            \n",
    "            # HEADING ANGLE\n",
    "            angle = np.clip((self.k.vehicle.get_orientation(q)[2]-180)/180, -1, 1)\n",
    "            obs.append(angle)\n",
    "            \n",
    "            # LANE, WAY AND QUEUE\n",
    "            if self.k.vehicle.get_route(q) == '': # just to fix a simulator bug\n",
    "                lane = [0.0, 0.0, 0.0]\n",
    "                way = [0.0, 0.0, 0.0]\n",
    "                queue = [0.0, 0.0, 0.0, 0.0]\n",
    "            else:\n",
    "                way = ways[self.k.vehicle.get_route(q)]\n",
    "                lane = [way[2], way[1], way[0]]\n",
    "                queue = queues[self.k.vehicle.get_route(q)[0]]\n",
    "            \n",
    "            obs = obs + lane + way + queue\n",
    "            \n",
    "            state_dict[q] = obs\n",
    "            \n",
    "        ord_vehs = order_vehicles(state_dict)\n",
    "        state = torch.zeros((len(ord_vehs), 14*len(ord_vehs)))\n",
    "        for k in range(len(ord_vehs)):\n",
    "            ego_state = torch.as_tensor([state_dict[ord_vehs[k]]])\n",
    "            for q in range(len(ord_vehs)):\n",
    "                if k != q:\n",
    "                    other_state = torch.as_tensor([state_dict[ord_vehs[q]]])\n",
    "                    ego_state = torch.cat((ego_state, other_state), dim=1)\n",
    "            state[k] = ego_state\n",
    "        \n",
    "        num_arrived = env.k.vehicle.get_num_arrived()\n",
    "        if num_arrived > 0:\n",
    "            if len(ids) > 0:\n",
    "                aug_col = torch.zeros((len(ids), 14*num_arrived))\n",
    "                aug_row = torch.zeros((num_arrived, 14*(state.shape[0]+num_arrived)))\n",
    "                state = torch.cat((state, aug_col), dim=1)\n",
    "                state = torch.cat((state, aug_row), dim=0)\n",
    "            else:\n",
    "                state = torch.zeros((num_arrived, 14*num_arrived))\n",
    "                \n",
    "        state = state.to(torch.float32)\n",
    "\n",
    "        return state.to(device), ord_vehs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb738fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.envs.ring.accel import ADDITIONAL_ENV_PARAMS\n",
    "from flow.core.params import EnvParams\n",
    "from flow.envs.ring.accel import AccelEnv\n",
    "\n",
    "env_params = EnvParams(additional_params=ADDITIONAL_ENV_PARAMS)\n",
    "\n",
    "from flow.core.params import SumoParams\n",
    "\n",
    "random_seed = np.random.choice(1000)\n",
    "sim_params = SumoParams(sim_step=0.25, render=False, seed=random_seed)\n",
    "\n",
    "from flow.core.params import TrafficLightParams\n",
    "\n",
    "traffic_lights = TrafficLightParams()\n",
    "\n",
    "from flow.core.params import InitialConfig\n",
    "\n",
    "initial_config = InitialConfig()\n",
    "\n",
    "from flow.core.params import VehicleParams\n",
    "\n",
    "vehicles = VehicleParams()\n",
    "\n",
    "from flow.controllers.rlcontroller import RLController\n",
    "from flow.controllers.routing_controllers import ContinuousRouter\n",
    "from flow.core.params import SumoCarFollowingParams\n",
    "\n",
    "vehicles.add(\"rl\",\n",
    "             acceleration_controller=(RLController, {}),\n",
    "             routing_controller=(ContinuousRouter, {}),\n",
    "             car_following_params=SumoCarFollowingParams(\n",
    "                speed_mode=\"aggressive\"),\n",
    "             num_vehicles=0)\n",
    "\n",
    "from flow.core.params import InFlows\n",
    "\n",
    "inflow = InFlows()\n",
    "\n",
    "inflow.add(veh_type=\"rl\",\n",
    "           edge=\"t_c\",\n",
    "           depart_lane=\"best\",\n",
    "           #vehs_per_hour=200,\n",
    "           #period=18,\n",
    "           probability=1/18\n",
    "          )\n",
    "inflow.add(veh_type=\"rl\",\n",
    "           edge=\"b_c\",\n",
    "           depart_lane=\"best\",\n",
    "           #vehs_per_hour=200,\n",
    "           #period=18,\n",
    "           probability=1/18\n",
    "          )\n",
    "inflow.add(veh_type=\"rl\",\n",
    "           edge=\"r_c\",\n",
    "           depart_lane=\"best\",\n",
    "           #vehs_per_hour=200\n",
    "           #period=18,\n",
    "           probability=1/18\n",
    "          )\n",
    "inflow.add(veh_type=\"rl\",\n",
    "           edge=\"l_c\",\n",
    "           depart_lane=\"best\",\n",
    "           #vehs_per_hour=200\n",
    "           #period=18,\n",
    "           probability=1/18\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202bfd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import NetParams\n",
    "\n",
    "net_params = NetParams(inflows=inflow, additional_params=ADDITIONAL_NET_PARAMS)\n",
    "\n",
    "flow_params = dict(\n",
    "    exp_tag='test',\n",
    "    env_name=SpeedEnv,\n",
    "    network=IntersectionNetwork,\n",
    "    simulator='traci',\n",
    "    sim=sim_params,\n",
    "    env=env_params,\n",
    "    net=net_params,\n",
    "    veh=vehicles,\n",
    "    initial=initial_config,\n",
    "    tls=traffic_lights,\n",
    ")\n",
    "\n",
    "# number of time steps\n",
    "flow_params['env'].horizon = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7315ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class PrioritizedReplayBuffer(object):\n",
    "    \n",
    "    def __init__(self, capacity, alpha=0.6, beta=0.4):\n",
    "        self.capacity = capacity # we use a power of 2 for capacity because it simplifies the code\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta  # importance-sampling, from initial value increasing to 1, often 0.4\n",
    "        self.epsilon = 0.01  # small amount to avoid zero priority\n",
    "        self.beta_increment_per_sampling = 1e-4  # annealing the bias, often 1e-3\n",
    "        \n",
    "        # maintain segment binary trees to take sum and find minimum over a range\n",
    "        self.priority_sum = [0 for _ in range(2*self.capacity)]\n",
    "        self.priority_min = [float('inf') for _ in range(2*self.capacity)]\n",
    "        \n",
    "        self.max_priority = 1. # current max priority to be assigned to new transitions\n",
    "        \n",
    "        self.data = {\n",
    "            'obs': [],\n",
    "            'action': np.zeros((capacity, 1)),\n",
    "            'reward': np.zeros((capacity, 1)),\n",
    "            'next_obs': [],\n",
    "            'not_done': np.zeros((capacity, 1)),\n",
    "        }\n",
    "        \n",
    "        self.next_idx = 0\n",
    "        self.size = 0\n",
    "        \n",
    "    def add(self, obs, action, reward, next_obs, done):\n",
    "        \n",
    "        idx = self.next_idx\n",
    "        \n",
    "        self.data['obs'].append(obs.detach().cpu().tolist())\n",
    "        self.data['action'][idx] = action.numpy()\n",
    "        self.data['reward'][idx] = reward.numpy()\n",
    "        self.data['next_obs'].append(next_obs.detach().cpu().tolist())\n",
    "        self.data['not_done'][idx] = 1. - done.numpy()\n",
    "        \n",
    "        self.next_idx = (idx + 1) % self.capacity\n",
    "        self.size = min(self.capacity, self.size + 1)\n",
    "        \n",
    "        priority_alpha = self.max_priority ** self.alpha # new samples get max_priority\n",
    "        \n",
    "        self._set_priority_min(idx, priority_alpha)\n",
    "        self._set_priority_sum(idx, priority_alpha)\n",
    "        \n",
    "    # set priority in binary segment tree for minimum\n",
    "    def _set_priority_min(self, idx, priority_alpha):\n",
    "        \n",
    "        idx += self.capacity # leaf of the binary tree\n",
    "        self.priority_min[idx] = priority_alpha\n",
    "        \n",
    "        while idx >= 2: # update tree by traversing along ancestors, continue until the root of the tree\n",
    "            idx //= 2 # get the index of the parent node\n",
    "            self.priority_min[idx] = min(self.priority_min[2*idx], self.priority_min[2*idx + 1]) # value of the\n",
    "            # parent node is the minimum of its two children\n",
    "            \n",
    "    # set priority in binary segment tree for sum\n",
    "    def _set_priority_sum(self, idx, priority):\n",
    "        \n",
    "        idx += self.capacity # leaf of the binary tree\n",
    "        self.priority_sum[idx] = priority\n",
    "        \n",
    "        while idx >= 2: # update tree by traversing along ancestors, continue until the root of the tree\n",
    "            idx //= 2 # get the index of the parent node\n",
    "            self.priority_sum[idx] = self.priority_sum[2*idx] + self.priority_sum[2*idx + 1] # value of the\n",
    "            # parent node is the sum of its two children\n",
    "            \n",
    "    def _sum(self):\n",
    "        return self.priority_sum[1] # the root node keeps the sum of all values\n",
    "    \n",
    "    def _min(self):\n",
    "        return self.priority_min[1] # the root node keeps the min of all values\n",
    "    \n",
    "    def find_prefix_sum_idx(self, prefix_sum):\n",
    "        \n",
    "        # start from the root\n",
    "        idx = 1\n",
    "        while idx < self.capacity:\n",
    "            if self.priority_sum[idx*2] >= prefix_sum: # if the sum of the left branch is higher than the required sum\n",
    "                idx = 2*idx # go to the left branch of the tree\n",
    "            else: # otherwise go to the right branch\n",
    "                prefix_sum -= self.priority_sum[idx*2] # and reduce the sum of left branch from required sum\n",
    "                idx = 2*idx + 1\n",
    "                \n",
    "        return idx - self.capacity # we are at the leaf node\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        \n",
    "        # initialize samples\n",
    "        samples = {\n",
    "            'weights': np.zeros(shape=(batch_size), dtype=np.float32),\n",
    "            'indexes': np.zeros(shape=(batch_size), dtype=np.int32)\n",
    "        }\n",
    "        \n",
    "        self.beta = np.amin([1., self.beta + self.beta_increment_per_sampling])  # max = 1\n",
    "        \n",
    "        # get sample indexes\n",
    "        for i in range(batch_size):\n",
    "            p = random.random() * self._sum()\n",
    "            idx = self.find_prefix_sum_idx(p)\n",
    "            samples['indexes'][i] = idx\n",
    "            \n",
    "        prob_min = self._min() / self._sum()\n",
    "        max_weight = (prob_min * self.size) ** (-self.beta)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            idx = samples['indexes'][i]\n",
    "            \n",
    "            prob = self.priority_sum[idx + self.capacity] / self._sum()\n",
    "            weight = (prob * self.size) ** (-self.beta)\n",
    "            \n",
    "            samples['weights'][i] = weight / max_weight\n",
    "            \n",
    "        for k, v in self.data.items():\n",
    "            if k == 'obs':\n",
    "                samples['obs'] = []\n",
    "                for i in samples['indexes']:\n",
    "                    samples['obs'].append(self.data['obs'][i])\n",
    "            elif k == 'next_obs':\n",
    "                samples['next_obs'] = []\n",
    "                for i in samples['indexes']:\n",
    "                    samples['next_obs'].append(self.data['next_obs'][i])\n",
    "            else:\n",
    "                samples[k] = v[samples['indexes']]\n",
    "            \n",
    "        return samples\n",
    "    \n",
    "    def update_priorities(self, indexes, priorities):\n",
    "        \n",
    "        for idx, priority in zip(indexes, priorities):\n",
    "            \n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "            priority_alpha = priority ** self.alpha\n",
    "            \n",
    "            self._set_priority_min(idx, priority_alpha)\n",
    "            self._set_priority_sum(idx, priority_alpha)\n",
    "            \n",
    "    def is_full(self):\n",
    "        return self.capacity == self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f9f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, ego_state_dim, action_dim, max_action):\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTMCell(ego_state_dim, 256)\n",
    "        self.fc1 = nn.Linear(256 + ego_state_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.pi = nn.Linear(256, action_dim)\n",
    "\n",
    "        self.max_action = max_action\n",
    "        \n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward_train(self, state):\n",
    "        \"\"\"\n",
    "        state is a list containing the elements in the batch: each element is in turn a list,\n",
    "        corresponding to the state dimension in that timestep (14 * num_veh)\n",
    "        \"\"\"\n",
    "        rnn_out = [] # this list will contain all the batch elements after the recursive layer (B, 270)\n",
    "        for i in range(len(state)): # for every element in the batch\n",
    "            current_state = torch.tensor(state[i], device=self.device, dtype=torch.float32) # take the corresponding state\n",
    "            num_vehs = current_state.shape[0] // 14 # compute the number of vehicles in that instant\n",
    "            current_state = current_state.view(num_vehs, 14) # reshape (Num_Veh, 14)\n",
    "            hx = torch.zeros(256, device=self.device, dtype=torch.float32) # initialize\n",
    "            cx = torch.zeros(256, device=self.device, dtype=torch.float32) # initialize\n",
    "            for j in range(num_vehs): # for every vehicle present in that instant\n",
    "                hx, cx = self.lstm(current_state[j], (hx, cx)) # iterate in the LSTM cell\n",
    "            hx = torch.cat((current_state[0], hx)) # concatenate the ego_state with the final LSTM output\n",
    "            rnn_out.append(hx) # compose the final list\n",
    "        x = torch.stack(rnn_out, dim=0) # transform it into a tensor\n",
    "        \n",
    "        # MLP part\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        \n",
    "        #out = self.max_action * torch.sigmoid(self.pi(x))\n",
    "        out = torch.tanh(self.pi(x))\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"\n",
    "        state is a (V, F*V) tensor\n",
    "        \"\"\"\n",
    "        num_vehs = state.shape[1] // 14 # compute the number of vehicles in that instant\n",
    "        if num_vehs == 0:\n",
    "            return torch.tensor([], device=self.device)\n",
    "        \n",
    "        rnn_out = []\n",
    "        for i in range(state.shape[0]): # for every vehicle\n",
    "            current_state = state[i].view(num_vehs, 14) # reshape (Num_Veh, 14)\n",
    "            hx = torch.zeros(256, device=self.device, dtype=torch.float32) # initialize\n",
    "            cx = torch.zeros(256, device=self.device, dtype=torch.float32) # initialize\n",
    "            for j in range(num_vehs): # for every vehicle present in that instant\n",
    "                hx, cx = self.lstm(current_state[j], (hx, cx)) # iterate in the LSTM cell\n",
    "            hx = torch.cat((current_state[0], hx)) # concatenate the ego_state with the final LSTM output\n",
    "            rnn_out.append(hx) # compose the final list\n",
    "        x = torch.stack(rnn_out, dim=0) # transform it into a tensor\n",
    "\n",
    "        # MLP part\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        \n",
    "        #out = self.max_action * torch.sigmoid(self.pi(x))\n",
    "        out = torch.tanh(self.pi(x))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, ego_state_dim, action_dim):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        self.lstm_1 = nn.LSTMCell(ego_state_dim, 256)\n",
    "        self.fc1_1 = nn.Linear(256 + ego_state_dim + action_dim, 1024)\n",
    "        self.fc2_1 = nn.Linear(1024, 1024)\n",
    "        self.fc3_1 = nn.Linear(1024, 512)\n",
    "        self.fc4_1 = nn.Linear(512, 256)\n",
    "        self.q_1 = nn.Linear(256, 1)\n",
    "\n",
    "        self.lstm_2 = nn.LSTMCell(ego_state_dim, 256)\n",
    "        self.fc1_2 = nn.Linear(256 + ego_state_dim + action_dim, 1024)\n",
    "        self.fc2_2 = nn.Linear(1024, 1024)\n",
    "        self.fc3_2 = nn.Linear(1024, 512)\n",
    "        self.fc4_2 = nn.Linear(512, 256)\n",
    "        self.q_2 = nn.Linear(256, 1)\n",
    "\n",
    "        \n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        \"\"\"\n",
    "        - state is a list containing the elements in the batch: each element is in turn a list,\n",
    "        corresponding to the state dimension in that timestep (14 * num_veh)\n",
    "        - action is a tensor of dimension (B) containing the actions of all the vehicles in the batch\n",
    "        \"\"\"\n",
    "        rnn_out_1 = [] # this list will contain all the batch elements after the recursive layer (B, 271)\n",
    "        rnn_out_2 = [] # this list will contain all the batch elements after the recursive layer (B, 271)\n",
    "        \n",
    "        for i in range(len(state)): # for every element in the batch\n",
    "            current_state = torch.tensor(state[i], device=self.device, dtype=torch.float32) # take the corresponding state\n",
    "            num_vehs = current_state.shape[0] // 14 # compute the number of vehicles in that instant\n",
    "            current_state = current_state.view(num_vehs, 14) # reshape (Num_Veh, 14)\n",
    "\n",
    "            hx_1 = torch.zeros(256, device=self.device, dtype=torch.float32) # initialize\n",
    "            cx_1 = torch.zeros(256, device=self.device, dtype=torch.float32) # initialize\n",
    "            hx_2 = torch.zeros(256, device=self.device, dtype=torch.float32) # initialize\n",
    "            cx_2 = torch.zeros(256, device=self.device, dtype=torch.float32) # initialize\n",
    "\n",
    "            for j in range(num_vehs): # for every vehicle present in that instant\n",
    "\n",
    "                hx_1, cx_1 = self.lstm_1(current_state[j], (hx_1, cx_1)) # iterate in the LSTM cell\n",
    "                hx_2, cx_2 = self.lstm_2(current_state[j], (hx_2, cx_2)) # iterate in the LSTM cell\n",
    "            \n",
    "            aug_state = torch.cat((current_state[0], action[i]))\n",
    "            \n",
    "            hx_1 = torch.cat((aug_state, hx_1)) # concatenate the ego_state with the final LSTM output\n",
    "            hx_2 = torch.cat((aug_state, hx_2)) # concatenate the ego_state with the final LSTM output\n",
    "            \n",
    "            rnn_out_1.append(hx_1) # compose the final list\n",
    "            rnn_out_2.append(hx_2) # compose the final list\n",
    "\n",
    "        x_1 = torch.stack(rnn_out_1, dim=0) # transform it into a tensor\n",
    "        x_2 = torch.stack(rnn_out_2, dim=0) # transform it into a tensor\n",
    "        \n",
    "        # MLP part 1\n",
    "        x_1 = F.relu(self.fc1_1(x_1))\n",
    "        x_1 = F.relu(self.fc2_1(x_1))\n",
    "        x_1 = F.relu(self.fc3_1(x_1))\n",
    "        x_1 = F.relu(self.fc4_1(x_1))\n",
    "\n",
    "        # MLP part 2\n",
    "        x_2 = F.relu(self.fc1_2(x_2))\n",
    "        x_2 = F.relu(self.fc2_2(x_2))\n",
    "        x_2 = F.relu(self.fc3_2(x_2))\n",
    "        x_2 = F.relu(self.fc4_2(x_2))\n",
    "        \n",
    "        out_1 = self.q_1(x_1)\n",
    "        out_2 = self.q_2(x_2)\n",
    "        \n",
    "        return out_1, out_2\n",
    "    \n",
    "    def Q1(self, state, action):\n",
    "        \n",
    "        rnn_out_1 = [] # this list will contain all the batch elements after the recursive layer (B, 271)\n",
    "        \n",
    "        for i in range(len(state)): # for every element in the batch\n",
    "            current_state = torch.tensor(state[i], device=self.device, dtype=torch.float32) # take the corresponding state\n",
    "            num_vehs = current_state.shape[0] // 14 # compute the number of vehicles in that instant\n",
    "            current_state = current_state.view(num_vehs, 14) # reshape (Num_Veh, 14)\n",
    "\n",
    "            hx_1 = torch.zeros(256, device=self.device, dtype=torch.float32) # initialize\n",
    "            cx_1 = torch.zeros(256, device=self.device, dtype=torch.float32) # initialize\n",
    "\n",
    "            for j in range(num_vehs): # for every vehicle present in that instant\n",
    "\n",
    "                hx_1, cx_1 = self.lstm_1(current_state[j], (hx_1, cx_1)) # iterate in the LSTM cell\n",
    "            \n",
    "            aug_state = torch.cat((current_state[0], action[i]))\n",
    "            \n",
    "            hx_1 = torch.cat((aug_state, hx_1)) # concatenate the ego_state with the final LSTM output\n",
    "            \n",
    "            rnn_out_1.append(hx_1) # compose the final list\n",
    "\n",
    "        x_1 = torch.stack(rnn_out_1, dim=0) # transform it into a tensor\n",
    "        \n",
    "        # MLP part\n",
    "        x_1 = F.relu(self.fc1_1(x_1))\n",
    "        x_1 = F.relu(self.fc2_1(x_1))\n",
    "        x_1 = F.relu(self.fc3_1(x_1))\n",
    "        x_1 = F.relu(self.fc4_1(x_1))\n",
    "        \n",
    "        out_1 = self.q_1(x_1)\n",
    "        \n",
    "        return out_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TD3(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        max_action,\n",
    "        discount=0.99,\n",
    "        tau=4e-3,\n",
    "        policy_noise=0.2,\n",
    "        noise_clip=0.3,\n",
    "        policy_freq=2,\n",
    "        filename='LSTM_AIM'\n",
    "    ):\n",
    "\n",
    "        self.actor = Actor(state_dim, action_dim, max_action)\n",
    "        self.actor_target = copy.deepcopy(self.actor)\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=1e-5)\n",
    "\n",
    "        self.critic = Critic(state_dim, action_dim)\n",
    "        self.critic_target = copy.deepcopy(self.critic)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "        self.max_action = max_action\n",
    "        self.discount = discount\n",
    "        self.tau = tau\n",
    "        self.policy_noise = policy_noise\n",
    "        self.noise_clip = noise_clip\n",
    "        self.policy_freq = policy_freq\n",
    "        self.filename = filename\n",
    "\n",
    "        self.total_it = 0\n",
    "\n",
    "\n",
    "    def select_action(self, state):\n",
    "        return self.actor.forward(state).detach().cpu()\n",
    "    \n",
    "    def mse(self, expected, targets, weights):\n",
    "        \"\"\"Custom loss function that takes into account the importance-sampling weights.\"\"\"\n",
    "        td_error = expected - targets\n",
    "        weighted_squared_error = weights * td_error * td_error\n",
    "        return torch.sum(weighted_squared_error) / torch.numel(weighted_squared_error)\n",
    "\n",
    "    def train(self, replay_buffer, batch_size=128):\n",
    "        self.total_it += 1\n",
    "        \n",
    "        for i in range(200):\n",
    "            # Sample replay buffer \n",
    "            batch = replay_buffer.sample(batch_size)\n",
    "            state, action, next_state, reward, not_done = batch['obs'], batch['action'], batch['next_obs'], batch['reward'], batch['not_done']\n",
    "            action = torch.tensor(action, device=self.actor.device, dtype=torch.float32)\n",
    "            reward = torch.tensor(reward, device=self.actor.device, dtype=torch.float32)\n",
    "            not_done = torch.tensor(not_done, device=self.actor.device)\n",
    "\n",
    "            weights = torch.tensor(batch['weights'], device=self.actor.device, dtype=torch.float32)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Select action according to policy and add clipped noise\n",
    "                noise = (\n",
    "                    torch.randn_like(action) * self.policy_noise\n",
    "                ).clamp(-self.noise_clip, self.noise_clip)\n",
    "\n",
    "                next_action = (\n",
    "                    self.actor_target.forward_train(next_state) + noise\n",
    "                ).clamp(-1, 1)\n",
    "\n",
    "                # Compute the target Q value\n",
    "                target_Q1, target_Q2 = self.critic_target(next_state, next_action)\n",
    "                target_Q = torch.min(target_Q1, target_Q2)\n",
    "                target_Q = reward + not_done * self.discount * target_Q\n",
    "\n",
    "            # Get current Q estimates\n",
    "            current_Q1, current_Q2 = self.critic(state, action)\n",
    "\n",
    "            # Compute critic loss\n",
    "            critic_loss = self.mse(current_Q1, target_Q, weights) + self.mse(current_Q2, target_Q, weights)\n",
    "\n",
    "            # Optimize the critic\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            self.critic_optimizer.step()\n",
    "\n",
    "            errors1 = np.abs((current_Q1 - target_Q).detach().cpu().numpy())\n",
    "            replay_buffer.update_priorities(batch['indexes'], errors1)\n",
    "\n",
    "            # Delayed policy updates\n",
    "            if i % self.policy_freq == 0 and i > 0:\n",
    "\n",
    "                # Compute actor losse\n",
    "                actor_loss = -self.critic.Q1(state, self.actor.forward_train(state)).mean()\n",
    "\n",
    "                # Optimize the actor \n",
    "                self.actor_optimizer.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                self.actor_optimizer.step()\n",
    "\n",
    "                # Update the frozen target models\n",
    "                for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "                    target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "                for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "                    target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "\n",
    "    def save(self):\n",
    "        filename = self.filename\n",
    "        torch.save(self.critic.state_dict(), filename + \"_critic\")\n",
    "        torch.save(self.critic_optimizer.state_dict(), filename + \"_critic_optimizer\")\n",
    "\n",
    "        torch.save(self.actor.state_dict(), filename + \"_actor\")\n",
    "        torch.save(self.actor_optimizer.state_dict(), filename + \"_actor_optimizer\")\n",
    "\n",
    "\n",
    "    def load(self):\n",
    "        filename = self.filename\n",
    "        self.critic.load_state_dict(torch.load(filename + \"_critic\"))\n",
    "        self.critic_optimizer.load_state_dict(torch.load(filename + \"_critic_optimizer\"))\n",
    "        self.critic_target = copy.deepcopy(self.critic)\n",
    "\n",
    "        self.actor.load_state_dict(torch.load(filename + \"_actor\"))\n",
    "        self.actor_optimizer.load_state_dict(torch.load(filename + \"_actor_optimizer\"))\n",
    "        self.actor_target = copy.deepcopy(self.actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65379d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(state):\n",
    "    if state.shape[0] > 0:\n",
    "        while torch.sum(state[-1,:]) == 0:\n",
    "            state = state[:-1,:state.shape[1]-14]\n",
    "            if state.shape[0] == 0:\n",
    "                break\n",
    "        return state\n",
    "    else:\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177ae23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from flow.utils.registry import make_create_env\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Get the env name and a creator for the environment.\n",
    "create_env, _ = make_create_env(flow_params)\n",
    "# Create the environment.\n",
    "env = create_env()\n",
    "\n",
    "num_eps = 1000000\n",
    "max_ep_steps = env.env_params.horizon\n",
    "total_steps = 0\n",
    "returns_list = []\n",
    "ep_steps_list = []\n",
    "\n",
    "state_dim = 14\n",
    "action_dim = 1\n",
    "max_action = 13.9/2\n",
    "\n",
    "memory = PrioritizedReplayBuffer(2**20)\n",
    "aim = TD3(\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        max_action,\n",
    "        discount=0.99,\n",
    "        tau=4e-3,\n",
    "        policy_noise=0.2,\n",
    "        noise_clip=0.5,\n",
    "        policy_freq=2,\n",
    "        filename='LSTM_AIM')\n",
    "\n",
    "def rl_actions(state):\n",
    "    num = state.shape[0]\n",
    "    actions = torch.randn((num,), device=\"cuda\").clamp(-1, 1)\n",
    "    return actions.detach().cpu()\n",
    "\n",
    "for i in range(num_eps):\n",
    "    returns = 0\n",
    "    ep_steps = 0\n",
    "    \n",
    "    # state is a 2-dim tensor\n",
    "    state = env.reset() # (V, F*V) where V: number of vehicles and F: number of features of each vehicle \n",
    "\n",
    "    for j in range(max_ep_steps):    \n",
    "\n",
    "        # actions: (V,) ordered tensor\n",
    "        if i > 0:\n",
    "            actions = aim.select_action(state)\n",
    "            noise = (\n",
    "                torch.randn_like(actions) * 0.1).clamp(-0.5, 0.5)\n",
    "            actions = (actions + noise).clamp(-1, 1)\n",
    "        else:\n",
    "            actions = rl_actions(state)\n",
    "        \n",
    "        # next_state: (V, F*V) ordered tensor\n",
    "        # reward: (V,) ordered tensor\n",
    "        # done: (V,) ordered tensor\n",
    "        # crash: boolean\n",
    "        \n",
    "        next_state, reward, done, crash = env.step(actions*max_action + max_action)\n",
    "        \n",
    "        if state.shape[0] > 0:\n",
    "            for k in range(state.shape[0]):\n",
    "                memory.add(state[k,:], actions[k], reward[k], next_state[k,:], done[k])\n",
    "        if total_steps % 400 == 0 and i > 0:\n",
    "            aim.train(memory)\n",
    "\n",
    "        state = next_state\n",
    "        state = trim(state)\n",
    "        \n",
    "        returns += sum(reward.tolist())\n",
    "        ep_steps += 1\n",
    "        total_steps += 1\n",
    "        \n",
    "        if crash:\n",
    "            break\n",
    "        \n",
    "    returns_list.append(returns)\n",
    "    ep_steps_list.append(ep_steps)\n",
    "    print('Episode number: {}, Episode steps: {}, Episode return: {}'.format(i, ep_steps, returns))\n",
    "    np.save('results/returns.npy', returns_list)\n",
    "    np.save('results/ep_steps.npy', ep_steps_list)\n",
    "    \n",
    "np.save('results/num_eps.npy', np.arange(num_eps))\n",
    "aim.save()\n",
    "env.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f55c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# capire cosa vuol dire optimizer epochs\n",
    "# testare repo del vecchio paper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:flow] *",
   "language": "python",
   "name": "conda-env-flow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
